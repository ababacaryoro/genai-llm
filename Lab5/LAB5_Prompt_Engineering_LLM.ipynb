{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "6b1bfcf5",
      "metadata": {
        "id": "6b1bfcf5"
      },
      "source": [
        "# LAB : Prompt Engineering pour les LLMs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rTANLs00VIbT",
      "metadata": {
        "id": "rTANLs00VIbT"
      },
      "source": [
        "### Installation des d√©pendances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce21aaeb",
      "metadata": {
        "id": "ce21aaeb"
      },
      "outputs": [],
      "source": [
        "# Commandes bash √† ex√©cuter dans un terminal:\n",
        "# # Cr√©er un environnement virtuel (recommand√©)\n",
        "# python -m venv llm_lab_env\n",
        "# source llm_lab_env/bin/activate  # Linux/Mac\n",
        "# # llm_lab_env\\Scripts\\activate  # Windows\n",
        "#\n",
        "# # Installer les packages n√©cessaires\n",
        "# pip install openai huggingface_hub tiktoken deepeval python-dotenv requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "D7HN00CuWm23",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "D7HN00CuWm23",
        "outputId": "b564a204-1cb4-453b-83ea-8eec68b3f3d0"
      },
      "outputs": [],
      "source": [
        "!pip install openai huggingface_hub tiktoken deepeval python-dotenv requests"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c9412d8",
      "metadata": {
        "id": "7c9412d8"
      },
      "source": [
        "### Configuration des cl√©s API\n",
        "\n",
        "Cr√©ez un fichier `.env` √† la racine de votre projet :"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24d9b575",
      "metadata": {
        "id": "24d9b575"
      },
      "source": [
        "**Configuration `.env`:**\n",
        "```\n",
        "# ============================================\n",
        "# CONFIGURATION DES CL√âS API\n",
        "# ============================================\n",
        "\n",
        "# Cl√© API OpenAI (obligatoire pour certains exercices)\n",
        "OPENAI_API_KEY=sk-votre-cle-api-openai\n",
        "\n",
        "# Cl√© API Hugging Face (gratuit - cr√©er un compte sur huggingface.co)\n",
        "HF_TOKEN=hf_votre-token-huggingface\n",
        "\n",
        "# ============================================\n",
        "# PARAM√àTRES PERSONNALISABLES\n",
        "# ============================================\n",
        "\n",
        "# Mod√®le OpenAI par d√©faut\n",
        "DEFAULT_OPENAI_MODEL=gpt-4o-mini\n",
        "\n",
        "# Mod√®le Hugging Face gratuit par d√©faut\n",
        "DEFAULT_HF_MODEL=meta-llama/Meta-Llama-3-8B-Instruct\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2689121b",
      "metadata": {
        "id": "2689121b"
      },
      "source": [
        "### Script d'initialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e81f3940",
      "metadata": {
        "id": "e81f3940"
      },
      "outputs": [],
      "source": [
        "# config.py\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "class Config:\n",
        "    OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "    HF_TOKEN = os.getenv(\"HF_TOKEN\")\n",
        "    DEFAULT_OPENAI_MODEL = os.getenv(\"DEFAULT_OPENAI_MODEL\", \"gpt-5-nano\")\n",
        "    DEFAULT_HF_MODEL = os.getenv(\"DEFAULT_HF_MODEL\", \"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
        "\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52e5f513",
      "metadata": {
        "id": "52e5f513"
      },
      "source": [
        "---\n",
        "\n",
        "## Partie 1 : Comprendre les Tokens et la Tokenisation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "z6h1RHo1VgvQ",
      "metadata": {
        "id": "z6h1RHo1VgvQ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Exercice 1 : Comprendre la tokenisation\n",
        "Objectif : Visualiser comment le texte est d√©coup√© en tokens\n",
        "\"\"\"\n",
        "\n",
        "import tiktoken\n",
        "\n",
        "def analyser_tokens(texte: str, modele: str = \"gpt-5-nano\"):\n",
        "    \"\"\"\n",
        "    Analyse la tokenisation d'un texte pour un mod√®le donn√©.\n",
        "\n",
        "    Args:\n",
        "        texte: Le texte √† analyser\n",
        "        modele: Le mod√®le pour lequel tokeniser (gpt-4, gpt-3.5-turbo, etc.)\n",
        "    \"\"\"\n",
        "    # Obtenir l'encodeur pour le mod√®le\n",
        "    encodeur = tiktoken.encoding_for_model(modele)\n",
        "\n",
        "    # Tokeniser le texte\n",
        "    tokens = encodeur.encode(texte)\n",
        "\n",
        "    # Afficher les r√©sultats\n",
        "    print(f\"Texte original : '{texte}'\")\n",
        "    print(f\"Nombre de tokens : {len(tokens)}\")\n",
        "    print(f\"Ratio caract√®res/tokens : {len(texte)/len(tokens):.2f}\")\n",
        "    print(f\"\\n D√©tail des tokens :\")\n",
        "\n",
        "    for i, token_id in enumerate(tokens):\n",
        "        token_texte = encodeur.decode([token_id])\n",
        "        print(f\"  Token {i+1}: ID={token_id:6d} ‚Üí '{token_texte}'\")\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0F7oV8L5W6HK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0F7oV8L5W6HK",
        "outputId": "67f93ecc-9098-4b82-888d-1c52f6dfd389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "ANALYSE DE TOKENISATION\n",
            "============================================================\n",
            "Texte original : 'Hello, world!'\n",
            "Nombre de tokens : 4\n",
            "Ratio caract√®res/tokens : 3.25\n",
            "\n",
            " D√©tail des tokens :\n",
            "  Token 1: ID= 13225 ‚Üí 'Hello'\n",
            "  Token 2: ID=    11 ‚Üí ','\n",
            "  Token 3: ID=  2375 ‚Üí ' world'\n",
            "  Token 4: ID=     0 ‚Üí '!'\n",
            "------------------------------------------------------------\n",
            "Texte original : 'Bonjour le monde !'\n",
            "Nombre de tokens : 4\n",
            "Ratio caract√®res/tokens : 4.50\n",
            "\n",
            " D√©tail des tokens :\n",
            "  Token 1: ID= 45751 ‚Üí 'Bonjour'\n",
            "  Token 2: ID=   505 ‚Üí ' le'\n",
            "  Token 3: ID= 15807 ‚Üí ' monde'\n",
            "  Token 4: ID=  1073 ‚Üí ' !'\n",
            "------------------------------------------------------------\n",
            "Texte original : 'L'intelligence artificielle transforme notre quotidien.'\n",
            "Nombre de tokens : 9\n",
            "Ratio caract√®res/tokens : 6.11\n",
            "\n",
            " D√©tail des tokens :\n",
            "  Token 1: ID=    43 ‚Üí 'L'\n",
            "  Token 2: ID= 37062 ‚Üí ''int'\n",
            "  Token 3: ID= 33465 ‚Üí 'elligence'\n",
            "  Token 4: ID=105453 ‚Üí ' artific'\n",
            "  Token 5: ID= 22380 ‚Üí 'ielle'\n",
            "  Token 6: ID=184109 ‚Üí ' transforme'\n",
            "  Token 7: ID= 12092 ‚Üí ' notre'\n",
            "  Token 8: ID= 59486 ‚Üí ' quotidien'\n",
            "  Token 9: ID=    13 ‚Üí '.'\n",
            "------------------------------------------------------------\n",
            "Texte original : 'The quick brown fox jumps over the lazy dog.'\n",
            "Nombre de tokens : 10\n",
            "Ratio caract√®res/tokens : 4.40\n",
            "\n",
            " D√©tail des tokens :\n",
            "  Token 1: ID=   976 ‚Üí 'The'\n",
            "  Token 2: ID=  4853 ‚Üí ' quick'\n",
            "  Token 3: ID= 19705 ‚Üí ' brown'\n",
            "  Token 4: ID= 68347 ‚Üí ' fox'\n",
            "  Token 5: ID= 65613 ‚Üí ' jumps'\n",
            "  Token 6: ID=  1072 ‚Üí ' over'\n",
            "  Token 7: ID=   290 ‚Üí ' the'\n",
            "  Token 8: ID= 29082 ‚Üí ' lazy'\n",
            "  Token 9: ID=  6446 ‚Üí ' dog'\n",
            "  Token 10: ID=    13 ‚Üí '.'\n",
            "------------------------------------------------------------\n",
            "Texte original : '12345 + 67890 = 80235'\n",
            "Nombre de tokens : 10\n",
            "Ratio caract√®res/tokens : 2.10\n",
            "\n",
            " D√©tail des tokens :\n",
            "  Token 1: ID=  7633 ‚Üí '123'\n",
            "  Token 2: ID=  2548 ‚Üí '45'\n",
            "  Token 3: ID=   659 ‚Üí ' +'\n",
            "  Token 4: ID=   220 ‚Üí ' '\n",
            "  Token 5: ID= 30833 ‚Üí '678'\n",
            "  Token 6: ID=  2744 ‚Üí '90'\n",
            "  Token 7: ID=   314 ‚Üí ' ='\n",
            "  Token 8: ID=   220 ‚Üí ' '\n",
            "  Token 9: ID= 24741 ‚Üí '802'\n",
            "  Token 10: ID=  2467 ‚Üí '35'\n",
            "------------------------------------------------------------\n",
            "Texte original : 'üöÄ Les √©mojis sont-ils bien tokenis√©s ? ü§ñ'\n",
            "Nombre de tokens : 14\n",
            "Ratio caract√®res/tokens : 2.86\n",
            "\n",
            " D√©tail des tokens :\n",
            "  Token 1: ID=112927 ‚Üí 'ÔøΩ'\n",
            "  Token 2: ID=   222 ‚Üí 'ÔøΩ'\n",
            "  Token 3: ID=  7029 ‚Üí ' Les'\n",
            "  Token 4: ID=  1212 ‚Üí ' √©'\n",
            "  Token 5: ID=  3690 ‚Üí 'mo'\n",
            "  Token 6: ID=137286 ‚Üí 'jis'\n",
            "  Token 7: ID=  5242 ‚Üí ' sont'\n",
            "  Token 8: ID= 94325 ‚Üí '-ils'\n",
            "  Token 9: ID=  5340 ‚Üí ' bien'\n",
            "  Token 10: ID=  6602 ‚Üí ' token'\n",
            "  Token 11: ID= 58890 ‚Üí 'is√©s'\n",
            "  Token 12: ID=  1423 ‚Üí ' ?'\n",
            "  Token 13: ID= 93643 ‚Üí ' ÔøΩ'\n",
            "  Token 14: ID=   244 ‚Üí 'ÔøΩ'\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Exercice 1.1 : Comparez la tokenisation de ces textes\n",
        "textes_test = [\n",
        "    \"Hello, world!\",\n",
        "    \"Bonjour le monde !\",\n",
        "    \"L'intelligence artificielle transforme notre quotidien.\",\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"12345 + 67890 = 80235\",\n",
        "    \"üöÄ Les √©mojis sont-ils bien tokenis√©s ? ü§ñ\",\n",
        "]\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"ANALYSE DE TOKENISATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for texte in textes_test:\n",
        "    analyser_tokens(texte)\n",
        "    print(\"-\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "0596e33b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0596e33b",
        "outputId": "6b6e69a2-020d-4488-f7ba-f71a6d9aa575"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üí∞ Estimation des co√ªts pour 1000 requ√™tes avec 500 tokens input et 200 tokens output:\n",
            "  Co√ªt total estim√© : $0.1050\n"
          ]
        }
      ],
      "source": [
        "# Exercice 1.2 : Calculez le co√ªt approximatif\n",
        "# Prix GPT-4o-mini : ~$0.15 / 1M tokens input, ~$0.60 / 1M tokens output\n",
        "def calculer_cout(nb_tokens_input: int, nb_tokens_output: int, modele: str = \"gpt-5-nano\"):\n",
        "    \"\"\"\n",
        "    Calcule le co√ªt approximatif d'une requ√™te.\n",
        "\n",
        "    TODO: Compl√©tez cette fonction en utilisant les tarifs actuels\n",
        "    R√©f√©rence : https://platform.openai.com/docs/pricing\n",
        "    \"\"\"\n",
        "    # üí° Personnalisez les tarifs selon votre mod√®le\n",
        "    tarifs = {\n",
        "        \"gpt-4o-mini\": {\"input\": 0.15/1000000, \"output\": 0.60/1000000},\n",
        "        \"gpt-5-nano\": {\"input\": 0.05/1000000, \"output\": 0.4/1000000},\n",
        "        \"gpt-4o\": {\"input\": 2.50/1000000, \"output\": 10.00/1000000},\n",
        "        # Ajoutez d'autres mod√®les ici\n",
        "    }\n",
        "\n",
        "    if modele not in tarifs:\n",
        "        print(f\"‚ö†Ô∏è Mod√®le {modele} non trouv√©, utilisation de gpt-4o-mini\")\n",
        "        modele = \"gpt-4o-mini\"\n",
        "\n",
        "    cout_input = nb_tokens_input * tarifs[modele][\"input\"]\n",
        "    cout_output = nb_tokens_output * tarifs[modele][\"output\"]\n",
        "\n",
        "    return {\n",
        "        \"input\": cout_input,\n",
        "        \"output\": cout_output,\n",
        "        \"total\": cout_input + cout_output\n",
        "    }\n",
        "\n",
        "# Test du calcul de co√ªt\n",
        "print(\"\\nüí∞ Estimation des co√ªts pour 1000 requ√™tes avec 500 tokens input et 200 tokens output:\")\n",
        "cout = calculer_cout(500 * 1000, 200 * 1000)\n",
        "print(f\"  Co√ªt total estim√© : ${cout['total']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bdaa49f9",
      "metadata": {
        "id": "bdaa49f9"
      },
      "source": [
        "---\n",
        "\n",
        "## Partie 2 : Configuration des Param√®tres LLM\n",
        "\n",
        "Les LLMs g√©n√®rent du texte en pr√©disant le token suivant bas√© sur une **distribution de probabilit√©s**. Chaque token possible a une probabilit√© associ√©e.\n",
        "\n",
        "**Param√®tres cl√©s :**\n",
        "\n",
        "| Param√®tre | Plage | Effet |\n",
        "|-----------|-------|-------|\n",
        "| **Temperature** | 0.0 - 2.0 | Contr√¥le la \"cr√©ativit√©\" (randomness) |\n",
        "| **Top-p** | 0.0 - 1.0 | Nucleus sampling - cumul des probabilit√©s |\n",
        "| **Top-k** | 1 - ‚àû | Limite le nombre de tokens candidats |\n",
        "\n",
        "### Pratique : Exp√©rimenter avec les Param√®tres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "j1qXmFA1YVwF",
      "metadata": {
        "id": "j1qXmFA1YVwF"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Exercice 2 : Exp√©rimenter avec les param√®tres des LLMs\n",
        "Objectif : Comprendre l'impact de temperature, top-p et top-k\n",
        "\"\"\"\n",
        "\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def generer_avec_parametres(\n",
        "    prompt: str,\n",
        "    temperature: float = 1.0,\n",
        "    top_p: float = 1.0,\n",
        "    max_tokens: int = 100,\n",
        "    n_generations: int = 3,\n",
        "    model: str = \"gpt-4o-mini\"\n",
        "):\n",
        "    \"\"\"\n",
        "    G√©n√®re plusieurs r√©ponses avec les m√™mes param√®tres pour observer la variabilit√©.\n",
        "\n",
        "    Args:\n",
        "        prompt: Le prompt √† envoyer au mod√®le\n",
        "        temperature: Contr√¥le la randomness (0=d√©terministe, 2=tr√®s cr√©atif)\n",
        "        top_p: Nucleus sampling (0.1=tr√®s focalis√©, 1.0=tous les tokens)\n",
        "        max_tokens: Nombre maximum de tokens √† g√©n√©rer\n",
        "        n_generations: Nombre de g√©n√©rations √† effectuer\n",
        "        model: Mod√®le √† utiliser\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Param√®tres : temperature={temperature}, top_p={top_p}\")\n",
        "    print(f\"Prompt : {prompt[:50]}...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    reponses = []\n",
        "    for i in range(n_generations):\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=temperature,\n",
        "            top_p=top_p,\n",
        "            max_tokens=max_tokens\n",
        "        )\n",
        "        reponse = response.choices[0].message.content\n",
        "        reponses.append(reponse)\n",
        "        print(f\"\\nG√©n√©ration {i+1}:\\n{reponse}\")\n",
        "\n",
        "    # Analyse de la variabilit√©\n",
        "    mots_uniques = set()\n",
        "    for r in reponses:\n",
        "        mots_uniques.update(r.lower().split())\n",
        "\n",
        "    print(f\"\\nAnalyse : {len(mots_uniques)} mots uniques sur {n_generations} g√©n√©rations\")\n",
        "\n",
        "    return reponses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "hGOIn3bnYdMY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hGOIn3bnYdMY",
        "outputId": "3f317062-2f3a-4776-ac81-1335f6f04b1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "********************\n",
            "EXP√âRIENCE 1 : EFFET DE LA TEMP√âRATURE\n",
            "********************\n",
            "\n",
            "============================================================\n",
            "Param√®tres : temperature=0.0, top_p=1.0\n",
            "Prompt : √âcrivez le d√©but d'une histoire fantastique en une...\n",
            "============================================================\n",
            "\n",
            "G√©n√©ration 1:\n",
            "Dans un royaume oubli√© o√π les √©toiles murmuraient des secrets anciens, une jeune fille d√©couvrit une cl√© en argent scintillante enfouie sous les racines d'un arbre mill√©naire, promettant d'ouvrir la porte vers des mondes insoup√ßonn√©s.\n",
            "\n",
            "G√©n√©ration 2:\n",
            "Dans un royaume oubli√© o√π les √©toiles murmuraient des secrets anciens, une jeune fille d√©couvrit une cl√© en argent scintillante enfouie sous les racines d'un arbre mill√©naire, promettant d'ouvrir la porte vers des mondes insoup√ßonn√©s.\n",
            "\n",
            "G√©n√©ration 3:\n",
            "Dans un royaume oubli√© o√π les √©toiles murmuraient des secrets anciens, une jeune fille d√©couvrit une cl√© en argent scintillante enfouie sous les racines d'un arbre mill√©naire, promettant d'ouvrir la porte vers des mondes insoup√ßonn√©s.\n",
            "\n",
            "Analyse : 32 mots uniques sur 3 g√©n√©rations\n",
            "\n",
            "============================================================\n",
            "Param√®tres : temperature=0.5, top_p=1.0\n",
            "Prompt : √âcrivez le d√©but d'une histoire fantastique en une...\n",
            "============================================================\n",
            "\n",
            "G√©n√©ration 1:\n",
            "Dans un royaume oubli√© o√π les √©toiles murmuraient des secrets, une jeune fille d√©couvrit une cl√© en argent scintillante enfouie sous les racines d'un arbre mill√©naire, promettant d'ouvrir la porte vers un monde o√π la magie et le danger dansaient main dans la main.\n",
            "\n",
            "G√©n√©ration 2:\n",
            "Dans une for√™t o√π les arbres murmuraient des secrets oubli√©s, une jeune fille d√©couvrit une cl√© en argent scintillante, suspendue √† une branche, qui semblait l'appeler vers un destin myst√©rieux.\n",
            "\n",
            "G√©n√©ration 3:\n",
            "Dans un royaume oubli√©, o√π les √©toiles murmuraient des secrets anciens, une jeune fille d√©couvrit une cl√© en argent scintillante, capable d'ouvrir des portails vers des mondes que m√™me les l√©gendes n'osaient √©voquer.\n",
            "\n",
            "Analyse : 60 mots uniques sur 3 g√©n√©rations\n",
            "\n",
            "============================================================\n",
            "Param√®tres : temperature=1.0, top_p=1.0\n",
            "Prompt : √âcrivez le d√©but d'une histoire fantastique en une...\n",
            "============================================================\n",
            "\n",
            "G√©n√©ration 1:\n",
            "Dans un royaume cach√© sous un ciel cercl√© d'√©toiles chatoyantes, une jeune femme d√©couvrit une plume d'oiseau luminescente qui, selon la l√©gende, pouvait lib√©rer les souvenirs des anc√™tres oubli√©s.\n",
            "\n",
            "G√©n√©ration 2:\n",
            "Dans un village oubli√© o√π les murmures des anc√™tres dansaient avec la brume matinale, une jeune fille d√©couvrit un miroir ancien capable de refl√©ter non pas son image, mais les secrets des mondes cach√©s derri√®re le voile du quotidien.\n",
            "\n",
            "G√©n√©ration 3:\n",
            "Dans une for√™t o√π les arbres murmuraient des secrets oubli√©s, une jeune fille d√©couvrit un portail scintillant dissimul√© derri√®re un vieux ch√™ne, promettant de la plonger dans un monde o√π la magie n'√©tait pas qu'un r√™ve, mais une r√©alit√© tangible.\n",
            "\n",
            "Analyse : 72 mots uniques sur 3 g√©n√©rations\n",
            "\n",
            "============================================================\n",
            "Param√®tres : temperature=1.5, top_p=1.0\n",
            "Prompt : √âcrivez le d√©but d'une histoire fantastique en une...\n",
            "============================================================\n",
            "\n",
            "G√©n√©ration 1:\n",
            "Dans un royaume o√π les √©toiles murmuraient aux m√©l √©es mystiques du vent, une jeune vagabonde d√©couvrit, sous un porche oubli√©, une cl√© scintillante popich√©e avec une inscription √©nigmatique : \"L√† o√π le monde se croise, les puissances se lib√®rent.\"\n",
            "\n",
            "G√©n√©ration 2:\n",
            "Lorsqu'il d√©couvrit un ancien t√©lescope poussi√©reux au fond du grenier familial, Lucien ne se doutait pas qu'il imminence443155661 calamitudes.datas&i.ir–æ–∑—Å—Ç–≤–µ–Ω –±”ô—Ö jakiifiquementŸéŸäZ–≥”ô–Ω–∞–ª–∞—Ä ÿÆÿµŸàÿµ –∑–∞—Ç uzman –æ—Ç—á–µ—Ç –≥bmTRA zg ../ÿßŸÑÿ¨-re·Éê·É•·É™iDia‡§∞ Scottish runt teve.s —Ü–∏—Ä–±–∞–µ–≤Œ±TENbi–ê unless —Ñlm ÿ£ÿµ ŸàguardBagijzig–∏–Ω–∏ des–µ—á—å acerckhallahŸàÿß–æ–∑–∞—Ä kruiden ÿßŸÑÿ∑ÿßŸÇÿ©Îì§ÏùÄÈùë doorg –∏–º–µ–µ—Ç—Å—èownersonne\n",
            "\n",
            "G√©n√©ration 3:\n",
            "Sous l'ombres des s√©quoias mill√©naires, un enfant aux yeux d'√©meraudes d√©couvrit l‚Äôentr√©e d'un monde oubli√©, o√π la magie soufflait dans le murmure du vent et o√π les cr√©atures l√©gendaires √©taient √† la recherche d'un ancien porteur de lumi√®re.\n",
            "\n",
            "Analyse : 96 mots uniques sur 3 g√©n√©rations\n"
          ]
        }
      ],
      "source": [
        "# Exercice 2.1 : Comparez les effets de diff√©rentes temp√©ratures\n",
        "prompt_creatif = \"√âcrivez le d√©but d'une histoire fantastique en une phrase.\"\n",
        "\n",
        "print(\"\\n\" + \"*\" * 20)\n",
        "print(\"EXP√âRIENCE 1 : EFFET DE LA TEMP√âRATURE\")\n",
        "print(\"*\" * 20)\n",
        "\n",
        "# TODO: Testez avec temperature = 0.0, 0.5, 1.0, 1.5\n",
        "configurations_temp = [\n",
        "    {\"temperature\": 0.0, \"top_p\": 1.0},  # D√©terministe\n",
        "    {\"temperature\": 0.5, \"top_p\": 1.0},  # L√©g√®rement cr√©atif\n",
        "    {\"temperature\": 1.0, \"top_p\": 1.0},  # √âquilibr√©\n",
        "    {\"temperature\": 1.5, \"top_p\": 1.0},  # Tr√®s cr√©atif\n",
        "]\n",
        "\n",
        "for config in configurations_temp:\n",
        "    generer_avec_parametres(\n",
        "        prompt_creatif,\n",
        "        temperature=config[\"temperature\"],\n",
        "        top_p=config[\"top_p\"],\n",
        "        n_generations=3\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "H7DUUzWIY9Xh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "H7DUUzWIY9Xh",
        "outputId": "cd3e5863-b51e-4d20-f79e-38886f98da7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "********************\n",
            "EXP√âRIENCE 2 : EFFET DU TOP-P\n",
            "********************\n",
            "\n",
            "============================================================\n",
            "Param√®tres : temperature=1.0, top_p=0.1\n",
            "Prompt : √âcrivez le d√©but d'une histoire fantastique en une...\n",
            "============================================================\n",
            "\n",
            "G√©n√©ration 1:\n",
            "Dans un royaume oubli√© o√π les √©toiles murmuraient des secrets anciens, une jeune fille d√©couvrit une cl√© en argent scintillante enfouie sous les racines d'un arbre mill√©naire, promettant d'ouvrir la porte vers des mondes insoup√ßonn√©s.\n",
            "\n",
            "G√©n√©ration 2:\n",
            "Dans un royaume oubli√© o√π les √©toiles murmuraient des secrets anciens, une jeune fille d√©couvrit une cl√© en argent scintillante enfouie sous les racines d'un arbre mill√©naire, promettant d'ouvrir la porte vers des mondes insoup√ßonn√©s.\n",
            "\n",
            "G√©n√©ration 3:\n",
            "Dans un royaume oubli√© o√π les √©toiles murmuraient des secrets anciens, une jeune fille d√©couvrit une cl√© en argent scintillante enfouie sous les racines d'un arbre mill√©naire, promettant d'ouvrir la porte vers des mondes insoup√ßonn√©s.\n",
            "\n",
            "Analyse : 32 mots uniques sur 3 g√©n√©rations\n",
            "\n",
            "============================================================\n",
            "Param√®tres : temperature=1.0, top_p=0.5\n",
            "Prompt : √âcrivez le d√©but d'une histoire fantastique en une...\n",
            "============================================================\n",
            "\n",
            "G√©n√©ration 1:\n",
            "Dans un royaume oubli√© o√π les √©toiles murmuraient des secrets aux r√™veurs, une jeune fille d√©couvrit une cl√© en argent scintillante enfouie sous les racines d'un arbre mill√©naire, promettant d'ouvrir la porte vers des mondes insoup√ßonn√©s.\n",
            "\n",
            "G√©n√©ration 2:\n",
            "Dans un royaume oubli√© o√π les √©toiles murmuraient des secrets anciens, une jeune fille d√©couvrit une cl√© en argent scintillante, capable d'ouvrir la porte vers des mondes que seuls les r√™ves osaient explorer.\n",
            "\n",
            "G√©n√©ration 3:\n",
            "Dans un royaume cach√© derri√®re les nuages, o√π les arbres murmuraient des secrets anciens et les rivi√®res chantaient des m√©lodies oubli√©es, une jeune fille d√©couvrit une cl√© en argent scintillante, promise √† ouvrir la porte d'un monde o√π le temps n'existait pas.\n",
            "\n",
            "Analyse : 59 mots uniques sur 3 g√©n√©rations\n",
            "\n",
            "============================================================\n",
            "Param√®tres : temperature=1.0, top_p=0.9\n",
            "Prompt : √âcrivez le d√©but d'une histoire fantastique en une...\n",
            "============================================================\n",
            "\n",
            "G√©n√©ration 1:\n",
            "Dans un royaume o√π les nuages prenaient vie et les arbres murmuraient des secrets oubli√©s, une jeune fille d√©couvrit une cl√© en argent cach√©e sous les racines d'un vieux ch√™ne, ouvrant ainsi la porte √† un monde enchant√© qu'elle n'aurait jamais pu imaginer.\n",
            "\n",
            "G√©n√©ration 2:\n",
            "Dans un monde o√π les √©toiles murmuraient des secrets oubli√©s, une jeune fille nomm√©e Elara d√©couvrit une cl√© en argent grav√©e de runes anciennes, capable d'ouvrir la porte vers des royaumes ench√¢ss√©s dans la l√©gende.\n",
            "\n",
            "G√©n√©ration 3:\n",
            "Dans un royaume oubli√© o√π les √©toiles murmuraient des secrets anciens, une jeune fille d√©couvrit une cl√© en argent grav√©e de runes, capable d'ouvrir des portes vers des mondes que nul mortel n'avait os√© explorer.\n",
            "\n",
            "Analyse : 63 mots uniques sur 3 g√©n√©rations\n",
            "\n",
            "============================================================\n",
            "Param√®tres : temperature=1.0, top_p=1.0\n",
            "Prompt : √âcrivez le d√©but d'une histoire fantastique en une...\n",
            "============================================================\n",
            "\n",
            "G√©n√©ration 1:\n",
            "Dans un village oubli√©, o√π le temps semblait s'√™tre arr√™t√©, une lueur argent√©e √©mergea des profondeurs de la for√™t, promettant des secrets perdus et des aventures inimaginables.\n",
            "\n",
            "G√©n√©ration 2:\n",
            "Dans le c≈ìur d'une for√™t oubli√©e, o√π les arbres murmuraient des secrets anciens, une jeune fille d√©couvrit une cl√© en argent, scintillant faiblement sous la lueur d'une lune √©meraude, promettant d'ouvrir une porte vers un monde o√π les l√©gendes prenaient vie.\n",
            "\n",
            "G√©n√©ration 3:\n",
            "Dans un royaume oubli√©, o√π les √©toiles murmuraient des secrets aux for√™ts enchant√©es, une jeune fille d√©couvrit une cl√© scintillante se dressant au milieu des racines d'un vieux ch√™ne, promettant d'ouvrir la porte vers des mondes insoup√ßonn√©s.\n",
            "\n",
            "Analyse : 67 mots uniques sur 3 g√©n√©rations\n"
          ]
        }
      ],
      "source": [
        "# Exercice 2.2 : Comparez les effets de diff√©rents top_p\n",
        "print(\"\\n\" + \"*\" * 20)\n",
        "print(\"EXP√âRIENCE 2 : EFFET DU TOP-P\")\n",
        "print(\"*\" * 20)\n",
        "\n",
        "# TODO: Testez avec top_p = 0.1, 0.5, 0.9, 1.0\n",
        "configurations_top_p = [\n",
        "    {\"temperature\": 1.0, \"top_p\": 0.1},  # Tr√®s focalis√©\n",
        "    {\"temperature\": 1.0, \"top_p\": 0.5},  # Moyennement focalis√©\n",
        "    {\"temperature\": 1.0, \"top_p\": 0.9},  # Diversifi√©\n",
        "    {\"temperature\": 1.0, \"top_p\": 1.0},  # Maximum de diversit√©\n",
        "]\n",
        "\n",
        "for config in configurations_top_p:\n",
        "    generer_avec_parametres(\n",
        "        prompt_creatif,\n",
        "        temperature=config[\"temperature\"],\n",
        "        top_p=config[\"top_p\"],\n",
        "        n_generations=3\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "BY5qb_99ZIaU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BY5qb_99ZIaU",
        "outputId": "ef2d25e5-2305-4d06-8660-61c4782a1aaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "********************\n",
            "EXP√âRIENCE 3 : CAS D'USAGE PRATIQUES\n",
            "********************\n",
            "\n",
            "Cas d'usage : extraction_donnees\n",
            "\n",
            "============================================================\n",
            "Param√®tres : temperature=0.0, top_p=1.0\n",
            "Prompt : Extrayez les informations suivantes du texte : nom...\n",
            "============================================================\n",
            "\n",
            "G√©n√©ration 1:\n",
            "Nom : Jean Dupont  \n",
            "Date : 15 mars 2024  \n",
            "Montant : 50000 euros\n",
            "\n",
            "G√©n√©ration 2:\n",
            "Nom : Jean Dupont  \n",
            "Date : 15 mars 2024  \n",
            "Montant : 50000 euros\n",
            "\n",
            "Analyse : 11 mots uniques sur 2 g√©n√©rations\n",
            "\n",
            "Cas d'usage : redaction_creative\n",
            "\n",
            "============================================================\n",
            "Param√®tres : temperature=1.2, top_p=0.9\n",
            "Prompt : Proposez un slogan publicitaire original pour une ...\n",
            "============================================================\n",
            "\n",
            "G√©n√©ration 1:\n",
            "\"R√©veillez vos sens, pr√©servez la plan√®te : Savourez l'√©thique, go√ªtez l'engagement.\"\n",
            "\n",
            "G√©n√©ration 2:\n",
            "\"R√©veillez vos sens, pr√©servez la plan√®te : chaque tasse compte !\"\n",
            "\n",
            "Analyse : 15 mots uniques sur 2 g√©n√©rations\n",
            "\n",
            "Cas d'usage : code_generation\n",
            "\n",
            "============================================================\n",
            "Param√®tres : temperature=0.2, top_p=0.95\n",
            "Prompt : √âcrivez une fonction Python qui calcule la suite d...\n",
            "============================================================\n",
            "\n",
            "G√©n√©ration 1:\n",
            "Voici une fonction Python qui calcule la suite de Fibonacci. La suite de Fibonacci est une s√©quence o√π chaque nombre est la somme des deux pr√©c√©dents, g√©n√©ralement commenc√©e par 0 et 1. Voici une impl√©mentation simple :\n",
            "\n",
            "```python\n",
            "def fibonacci(n):\n",
            "    if n <= 0:\n",
            "        return []\n",
            "    elif n == 1:\n",
            "        return [0]\n",
            "    elif n == 2:\n",
            "        return [0, 1]\n",
            "    \n",
            "    fib_sequence = [0,\n",
            "\n",
            "G√©n√©ration 2:\n",
            "Bien s√ªr ! Voici une fonction Python qui calcule la suite de Fibonacci. La suite de Fibonacci est une s√©rie de nombres o√π chaque nombre est la somme des deux pr√©c√©dents, g√©n√©ralement commenc√©e par 0 et 1.\n",
            "\n",
            "Voici une impl√©mentation simple de la suite de Fibonacci en utilisant une approche it√©rative :\n",
            "\n",
            "```python\n",
            "def fibonacci(n):\n",
            "    if n <= 0:\n",
            "        return []\n",
            "    elif n == 1:\n",
            "        return [0]\n",
            "    elif n == 2:\n",
            "\n",
            "\n",
            "Analyse : 56 mots uniques sur 2 g√©n√©rations\n",
            "\n",
            "Cas d'usage : conversation\n",
            "\n",
            "============================================================\n",
            "Param√®tres : temperature=0.7, top_p=0.9\n",
            "Prompt : Que pensez-vous de l'intelligence artificielle ?...\n",
            "============================================================\n",
            "\n",
            "G√©n√©ration 1:\n",
            "L'intelligence artificielle (IA) est un domaine fascinant et en constante √©volution qui offre de nombreuses possibilit√©s et d√©fis. Voici quelques points de r√©flexion :\n",
            "\n",
            "1. **Avantages** : L'IA peut am√©liorer l'efficacit√© dans divers domaines, tels que la sant√©, les transports, l'√©ducation et l'industrie. Elle permet d'analyser de grandes quantit√©s de donn√©es, d'automatiser des t√¢ches r√©p√©titives et de fournir des solutions innovantes √† des probl√®mes complexes.\n",
            "\n",
            "2.\n",
            "\n",
            "G√©n√©ration 2:\n",
            "L'intelligence artificielle (IA) est un domaine fascinant et en constante √©volution qui offre de nombreuses opportunit√©s, mais qui soul√®ve √©galement des d√©fis √©thiques et sociaux. Voici quelques points de r√©flexion :\n",
            "\n",
            "1. **Avantages** : L'IA peut am√©liorer l'efficacit√© dans de nombreux secteurs, comme la sant√©, les transports, l'√©ducation et les services. Elle peut analyser de grandes quantit√©s de donn√©es rapidement, aidant √† prendre des d√©cisions √©clair√©es.\n",
            "\n",
            "2. **\n",
            "\n",
            "Analyse : 75 mots uniques sur 2 g√©n√©rations\n"
          ]
        }
      ],
      "source": [
        "# Exercice 2.3 : Cas d'usage pratiques\n",
        "print(\"\\n\" + \"*\" * 20)\n",
        "print(\"EXP√âRIENCE 3 : CAS D'USAGE PRATIQUES\")\n",
        "print(\"*\" * 20)\n",
        "\n",
        "cas_usage = {\n",
        "    \"extraction_donnees\": {\n",
        "        \"prompt\": \"Extrayez les informations suivantes du texte : nom, date, montant.\\nTexte: 'Le contrat sign√© par Jean Dupont le 15 mars 2024 porte sur un montant de 50000 euros.'\",\n",
        "        \"temperature\": 0.0,  # D√©terministe pour l'extraction\n",
        "        \"top_p\": 1.0\n",
        "    },\n",
        "    \"redaction_creative\": {\n",
        "        \"prompt\": \"Proposez un slogan publicitaire original pour une marque de caf√© √©co-responsable.\",\n",
        "        \"temperature\": 1.2,  # Cr√©atif pour la pub\n",
        "        \"top_p\": 0.9\n",
        "    },\n",
        "    \"code_generation\": {\n",
        "        \"prompt\": \"√âcrivez une fonction Python qui calcule la suite de Fibonacci.\",\n",
        "        \"temperature\": 0.2,  # Pr√©cis pour le code\n",
        "        \"top_p\": 0.95\n",
        "    },\n",
        "    \"conversation\": {\n",
        "        \"prompt\": \"Que pensez-vous de l'intelligence artificielle ?\",\n",
        "        \"temperature\": 0.7,  # √âquilibr√© pour la conversation\n",
        "        \"top_p\": 0.9\n",
        "    }\n",
        "}\n",
        "\n",
        "# üí° Personnalisez les param√®tres selon vos observations\n",
        "for nom, config in cas_usage.items():\n",
        "    print(f\"\\nCas d'usage : {nom}\")\n",
        "    generer_avec_parametres(\n",
        "        config[\"prompt\"],\n",
        "        temperature=config[\"temperature\"],\n",
        "        top_p=config[\"top_p\"],\n",
        "        n_generations=2\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "166061fe",
      "metadata": {
        "id": "166061fe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "19db67d7",
      "metadata": {
        "id": "19db67d7"
      },
      "source": [
        "---\n",
        "\n",
        "## Partie 3 : Les Composantes d'un Prompt Efficace\n",
        "\n",
        "### Structure d'un Prompt\n",
        "\n",
        "Un prompt efficace contient g√©n√©ralement √† minima :\n",
        "\n",
        "```\n",
        "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
        "‚îÇ  1. CONTEXTE / R√îLE                     ‚îÇ\n",
        "‚îÇ     \"Tu es un expert en...\"             ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ  2. INSTRUCTION                         ‚îÇ\n",
        "‚îÇ     \"Analyse le texte suivant...\"       ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ  3. DONN√âES D'ENTR√âE                    ‚îÇ\n",
        "‚îÇ     [Le contenu √† traiter]              ‚îÇ\n",
        "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
        "‚îÇ  4. FORMAT DE SORTIE                    ‚îÇ\n",
        "‚îÇ     \"R√©ponds en JSON avec...\"           ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "```\n",
        "\n",
        "### Exercice Pratique : Construire des Prompts Structur√©s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "bdc09e16",
      "metadata": {
        "id": "bdc09e16"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Exercice 3 : Construction de prompts structur√©s\n",
        "Objectif : Ma√Ætriser les composantes d'un prompt efficace\n",
        "\"\"\"\n",
        "\n",
        "from openai import OpenAI\n",
        "import json\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "class PromptBuilder:\n",
        "    \"\"\"\n",
        "    Classe pour construire des prompts structur√©s de mani√®re modulaire.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.contexte = \"\"\n",
        "        self.instruction = \"\"\n",
        "        self.donnees = \"\"\n",
        "        self.format_sortie = \"\"\n",
        "        self.exemples = []\n",
        "\n",
        "    def definir_contexte(self, role: str, expertise: str = \"\", contraintes: str = \"\"):\n",
        "        \"\"\"D√©finit le contexte et le r√¥le de l'assistant.\"\"\"\n",
        "        self.contexte = f\"Tu es {role}.\"\n",
        "        if expertise:\n",
        "            self.contexte += f\" Tu poss√®des une expertise en {expertise}.\"\n",
        "        if contraintes:\n",
        "            self.contexte += f\" {contraintes}\"\n",
        "        return self\n",
        "\n",
        "    def definir_instruction(self, action: str, details: str = \"\"):\n",
        "        \"\"\"D√©finit l'instruction principale.\"\"\"\n",
        "        self.instruction = action\n",
        "        if details:\n",
        "            self.instruction += f\" {details}\"\n",
        "        return self\n",
        "\n",
        "    def ajouter_donnees(self, donnees: str, label: str = \"Donn√©es\"):\n",
        "        \"\"\"Ajoute les donn√©es d'entr√©e.\"\"\"\n",
        "        self.donnees = f\"\\n\\n### {label}\\n{donnees}\"\n",
        "        return self\n",
        "\n",
        "    def definir_format(self, format_type: str, structure: dict = None):\n",
        "        \"\"\"D√©finit le format de sortie attendu.\"\"\"\n",
        "        self.format_sortie = f\"\\n\\n### Format de r√©ponse\\nR√©ponds au format {format_type}.\"\n",
        "        if structure:\n",
        "            self.format_sortie += f\"\\nStructure attendue:\\n```json\\n{json.dumps(structure, indent=2, ensure_ascii=False)}\\n```\"\n",
        "        return self\n",
        "\n",
        "    def ajouter_exemple(self, entree: str, sortie: str):\n",
        "        \"\"\"Ajoute un exemple (few-shot).\"\"\"\n",
        "        self.exemples.append({\"entree\": entree, \"sortie\": sortie})\n",
        "        return self\n",
        "\n",
        "    def construire(self) -> str:\n",
        "        \"\"\"Construit le prompt final.\"\"\"\n",
        "        prompt = self.contexte\n",
        "        prompt += f\"\\n\\n### Instruction\\n{self.instruction}\"\n",
        "\n",
        "        if self.exemples:\n",
        "            prompt += \"\\n\\n### Exemples\"\n",
        "            for i, ex in enumerate(self.exemples, 1):\n",
        "                prompt += f\"\\n\\n**Exemple {i}:**\\nEntr√©e: {ex['entree']}\\nSortie: {ex['sortie']}\"\n",
        "\n",
        "        prompt += self.donnees\n",
        "        prompt += self.format_sortie\n",
        "\n",
        "        return prompt\n",
        "\n",
        "def executer_prompt(prompt: str, model: str = \"gpt-4.1-mini\", temperature: float = 0.7):\n",
        "    \"\"\"Ex√©cute un prompt et retourne la r√©ponse.\"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=temperature\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "pUO1ejjtarl-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUO1ejjtarl-",
        "outputId": "d16f9fd1-d81c-4332-baa5-a30a2484c9d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "EXERCICE 3.1 : Analyse de Sentiment\n",
            "============================================================\n",
            "Prompt construit:\n",
            "----------------------------------------\n",
            "Tu es un analyste de sentiment expert. Tu poss√®des une expertise en l'analyse des avis clients. Tu dois √™tre pr√©cis et nuanc√© dans ton analyse.\n",
            "\n",
            "### Instruction\n",
            "Analyse le sentiment du texte suivant. Identifie les aspects positifs et n√©gatifs mentionn√©s.\n",
            "\n",
            "### Avis client\n",
            "\n",
            "Le nouveau restaurant du quartier est une vraie d√©ception. \n",
            "L'attente √©tait interminable malgr√© une r√©servation, \n",
            "et les plats, bien que joliment pr√©sent√©s, manquaient cruellement de saveur.\n",
            "Cependant, le service √©tait impeccable et le cadre vraiment agr√©able.\n",
            "\n",
            "\n",
            "### Format de r√©ponse\n",
            "R√©ponds au format JSON.\n",
            "Structure attendue:\n",
            "```json\n",
            "{\n",
            "  \"sentiment_global\": \"positif|n√©gatif|mixte\",\n",
            "  \"score\": \"0-10\",\n",
            "  \"aspects_positifs\": [\n",
            "    \"liste des points positifs\"\n",
            "  ],\n",
            "  \"aspects_negatifs\": [\n",
            "    \"liste des points n√©gatifs\"\n",
            "  ],\n",
            "  \"resume\": \"r√©sum√© en une phrase\"\n",
            "}\n",
            "```\n",
            "----------------------------------------\n",
            "\n",
            "R√©ponse du mod√®le:\n",
            "```json\n",
            "{\n",
            "  \"sentiment_global\": \"mixte\",\n",
            "  \"score\": 5,\n",
            "  \"aspects_positifs\": [\n",
            "    \"service impeccable\",\n",
            "    \"cadre agr√©able\",\n",
            "    \"pr√©sentation des plats soign√©e\"\n",
            "  ],\n",
            "  \"aspects_negatifs\": [\n",
            "    \"attente interminable malgr√© r√©servation\",\n",
            "    \"plats manquant de saveur\"\n",
            "  ],\n",
            "  \"resume\": \"Malgr√© un service irr√©prochable et un cadre plaisant, l'exp√©rience est ternie par une longue attente et des plats peu savoureux.\"\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "# Exercice 3.1 : Construire un prompt pour l'analyse de sentiment\n",
        "print(\"\\nEXERCICE 3.1 : Analyse de Sentiment\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# üí° Personnalisez ce texte avec vos propres donn√©es\n",
        "texte_analyse = \"\"\"\n",
        "Le nouveau restaurant du quartier est une vraie d√©ception.\n",
        "L'attente √©tait interminable malgr√© une r√©servation,\n",
        "et les plats, bien que joliment pr√©sent√©s, manquaient cruellement de saveur.\n",
        "Cependant, le service √©tait impeccable et le cadre vraiment agr√©able.\n",
        "\"\"\"\n",
        "\n",
        "prompt_sentiment = (\n",
        "    PromptBuilder()\n",
        "    .definir_contexte(\n",
        "        role=\"un analyste de sentiment expert\",\n",
        "        expertise=\"l'analyse des avis clients\",\n",
        "        contraintes=\"Tu dois √™tre pr√©cis et nuanc√© dans ton analyse.\"\n",
        "    )\n",
        "    .definir_instruction(\n",
        "        action=\"Analyse le sentiment du texte suivant.\",\n",
        "        details=\"Identifie les aspects positifs et n√©gatifs mentionn√©s.\"\n",
        "    )\n",
        "    .ajouter_donnees(texte_analyse, label=\"Avis client\")\n",
        "    .definir_format(\n",
        "        format_type=\"JSON\",\n",
        "        structure={\n",
        "            \"sentiment_global\": \"positif|n√©gatif|mixte\",\n",
        "            \"score\": \"0-10\",\n",
        "            \"aspects_positifs\": [\"liste des points positifs\"],\n",
        "            \"aspects_negatifs\": [\"liste des points n√©gatifs\"],\n",
        "            \"resume\": \"r√©sum√© en une phrase\"\n",
        "        }\n",
        "    )\n",
        "    .construire()\n",
        ")\n",
        "\n",
        "print(\"Prompt construit:\")\n",
        "print(\"-\"*40)\n",
        "print(prompt_sentiment)\n",
        "print(\"-\"*40)\n",
        "\n",
        "reponse = executer_prompt(prompt_sentiment, temperature=0.3)\n",
        "print(\"\\nR√©ponse du mod√®le:\")\n",
        "print(reponse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "58FHy-YBbYU-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58FHy-YBbYU-",
        "outputId": "e7d7d22b-2a66-4478-e641-b71f90edc6b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "EXERCICE 3.2 : Extraction d'Entit√©s Nomm√©es\n",
            "============================================================\n",
            "Entit√©s extraites:\n",
            "```json\n",
            "{\n",
            "  \"personnes\": [\"Tim Cook\"],\n",
            "  \"organisations\": [\"Apple Inc.\", \"AAPL\", \"R&D\"],\n",
            "  \"lieux\": [\"San Jos√©\", \"Cupertino\", \"Californie\"],\n",
            "  \"dates\": [\"WWDC 2024\", \"cette ann√©e\"],\n",
            "  \"montants\": [\"195 dollars\", \"2,5 milliards de dollars\"],\n",
            "  \"pourcentages\": [\"5%\"]\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "# Exercice 3.2 : Extraction d'entit√©s nomm√©es\n",
        "print(\"\\n\\nEXERCICE 3.2 : Extraction d'Entit√©s Nomm√©es\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# üí° Personnalisez ce texte\n",
        "texte_entites = \"\"\"\n",
        "Apple Inc., dirig√©e par Tim Cook, a annonc√© lors de la conf√©rence WWDC 2024\n",
        "√† San Jos√© le lancement de nouveaux produits. L'action AAPL a gagn√© 5%\n",
        "suite √† cette annonce, atteignant 195 dollars. Le d√©partement R&D,\n",
        "bas√© √† Cupertino en Californie, a investi 2,5 milliards de dollars\n",
        "dans le d√©veloppement de l'IA cette ann√©e.\n",
        "\"\"\"\n",
        "\n",
        "# TODO: Compl√©tez la construction du prompt\n",
        "prompt_entites = (\n",
        "    PromptBuilder()\n",
        "    .definir_contexte(\n",
        "        role=\"un sp√©cialiste en extraction d'information\",\n",
        "        # Ajoutez expertise et contraintes\n",
        "    )\n",
        "    .definir_instruction(\n",
        "        action=\"Extrais toutes les entit√©s nomm√©es du texte.\",\n",
        "        # Ajoutez des d√©tails\n",
        "    )\n",
        "    .ajouter_donnees(texte_entites, label=\"Texte √† analyser\")\n",
        "    .definir_format(\n",
        "        format_type=\"JSON\",\n",
        "        structure={\n",
        "            \"personnes\": [],\n",
        "            \"organisations\": [],\n",
        "            \"lieux\": [],\n",
        "            \"dates\": [],\n",
        "            \"montants\": [],\n",
        "            \"pourcentages\": []\n",
        "        }\n",
        "    )\n",
        "    .construire()\n",
        ")\n",
        "\n",
        "reponse_entites = executer_prompt(prompt_entites, temperature=0.1)\n",
        "print(\"Entit√©s extraites:\")\n",
        "print(reponse_entites)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0rzJgq0Mbmnz",
      "metadata": {
        "id": "0rzJgq0Mbmnz"
      },
      "source": [
        "## Partie 4 : Few-Shot Learning\n",
        "\n",
        "### Zero-Shot, One-Shot et Few-Shot\n",
        "\n",
        "| Approche | Description | Utilisation |\n",
        "|----------|-------------|-------------|\n",
        "| **Zero-Shot** | Aucun exemple fourni | T√¢ches simples et communes |\n",
        "| **One-Shot** | Un seul exemple | T√¢ches avec format sp√©cifique |\n",
        "| **Few-Shot** | Plusieurs exemples (2-5) | T√¢ches complexes ou inhabituelles |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "l2B_5_1KbsG3",
      "metadata": {
        "id": "l2B_5_1KbsG3"
      },
      "source": [
        "### Pratique : Comparaison des Approches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "Ooqpxr8abxUd",
      "metadata": {
        "id": "Ooqpxr8abxUd"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Exercice 4 : Few-Shot Learning\n",
        "Objectif : Comprendre l'impact des exemples sur la qualit√© des r√©ponses\n",
        "\"\"\"\n",
        "\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def few_shot_classification(texte: str, exemples: list = None, model: str = \"gpt-4o-mini\"):\n",
        "    \"\"\"\n",
        "    Effectue une classification de sentiment avec diff√©rents niveaux de few-shot.\n",
        "\n",
        "    Args:\n",
        "        texte: Le texte √† classifier\n",
        "        exemples: Liste de tuples (texte, label) pour le few-shot\n",
        "        model: Mod√®le √† utiliser\n",
        "    \"\"\"\n",
        "    # Construction du prompt\n",
        "    system_prompt = \"\"\"Tu es un classificateur de sentiment.\n",
        "    Classe chaque texte comme : POSITIF, N√âGATIF ou NEUTRE.\n",
        "    R√©ponds UNIQUEMENT avec l'un de ces trois mots.\"\"\"\n",
        "\n",
        "    user_prompt = \"\"\n",
        "\n",
        "    # Ajout des exemples few-shot\n",
        "    if exemples:\n",
        "        user_prompt += \"Voici des exemples de classification :\\n\\n\"\n",
        "        for ex_texte, ex_label in exemples:\n",
        "            user_prompt += f\"Texte: \\\"{ex_texte}\\\"\\nClassification: {ex_label}\\n\\n\"\n",
        "        user_prompt += \"---\\n\\n\"\n",
        "\n",
        "    user_prompt += f\"Texte √† classifier: \\\"{texte}\\\"\\nClassification:\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        temperature=0.0,\n",
        "        max_tokens=10\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "E4M7ZtJ-cC0C",
      "metadata": {
        "id": "E4M7ZtJ-cC0C"
      },
      "outputs": [],
      "source": [
        "# Textes de test\n",
        "textes_test = [\n",
        "    \"Ce produit a compl√®tement chang√© ma vie quotidienne, je suis ravi !\",\n",
        "    \"Le colis est arriv√© √† la date pr√©vue.\",\n",
        "    \"Franchement d√©cevant, je m'attendais √† beaucoup mieux pour ce prix.\",\n",
        "    \"Le design est correct mais la qualit√© laisse √† d√©sirer.\",\n",
        "    \"Je ne sais pas trop quoi penser de cet achat.\",\n",
        "]\n",
        "\n",
        "# Exemples pour le few-shot\n",
        "# Personnalisez ces exemples selon votre domaine\n",
        "exemples_few_shot = [\n",
        "    (\"Excellent produit, livraison rapide, je recommande vivement !\", \"POSITIF\"),\n",
        "    (\"Produit d√©fectueux, remboursement difficile, une catastrophe.\", \"N√âGATIF\"),\n",
        "    (\"Le produit correspond √† la description.\", \"NEUTRE\"),\n",
        "    (\"J'adore cette marque, c'est toujours de la qualit√© !\", \"POSITIF\"),\n",
        "    (\"D√©√ßu par la qualit√©, ne correspond pas aux photos.\", \"N√âGATIF\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "vJDA1yt-cFe0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJDA1yt-cFe0",
        "outputId": "1f53c86e-ce2c-41b1-8c73-95cd407034eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "COMPARAISON : ZERO-SHOT vs ONE-SHOT vs FEW-SHOT\n",
            "======================================================================\n",
            "\n",
            "Texte: \"Ce produit a compl√®tement chang√© ma vie quotidienn...\"\n",
            "  Zero-Shot  : POSITIF\n",
            "  One-Shot   : POSITIF\n",
            "  Three-Shot : POSITIF\n",
            "  Five-Shot  : POSITIF\n",
            "\n",
            "Texte: \"Le colis est arriv√© √† la date pr√©vue....\"\n",
            "  Zero-Shot  : POSITIF\n",
            "  One-Shot   : NEUTRE\n",
            "  Three-Shot : NEUTRE\n",
            "  Five-Shot  : NEUTRE\n",
            "\n",
            "Texte: \"Franchement d√©cevant, je m'attendais √† beaucoup mi...\"\n",
            "  Zero-Shot  : N√âGATIF\n",
            "  One-Shot   : N√âGATIF\n",
            "  Three-Shot : N√âGATIF\n",
            "  Five-Shot  : N√âGATIF\n",
            "\n",
            "Texte: \"Le design est correct mais la qualit√© laisse √† d√©s...\"\n",
            "  Zero-Shot  : N√âGATIF\n",
            "  One-Shot   : N√âGATIF\n",
            "  Three-Shot : N√âGATIF\n",
            "  Five-Shot  : N√âGATIF\n",
            "\n",
            "Texte: \"Je ne sais pas trop quoi penser de cet achat....\"\n",
            "  Zero-Shot  : NEUTRE\n",
            "  One-Shot   : NEUTRE\n",
            "  Three-Shot : NEUTRE\n",
            "  Five-Shot  : NEUTRE\n"
          ]
        }
      ],
      "source": [
        "# Exercice 4.1 : Comparaison Zero-Shot vs Few-Shot\n",
        "print(\"=\"*70)\n",
        "print(\"COMPARAISON : ZERO-SHOT vs ONE-SHOT vs FEW-SHOT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "resultats = {\n",
        "    \"zero_shot\": [],\n",
        "    \"one_shot\": [],\n",
        "    \"three_shot\": [],\n",
        "    \"five_shot\": []\n",
        "}\n",
        "\n",
        "for texte in textes_test:\n",
        "    print(f\"\\nTexte: \\\"{texte[:50]}...\\\"\")\n",
        "\n",
        "    # Zero-Shot\n",
        "    res_zero = few_shot_classification(texte, exemples=None)\n",
        "    resultats[\"zero_shot\"].append(res_zero)\n",
        "    print(f\"  Zero-Shot  : {res_zero}\")\n",
        "\n",
        "    # One-Shot\n",
        "    res_one = few_shot_classification(texte, exemples=exemples_few_shot[:1])\n",
        "    resultats[\"one_shot\"].append(res_one)\n",
        "    print(f\"  One-Shot   : {res_one}\")\n",
        "\n",
        "    # Three-Shot\n",
        "    res_three = few_shot_classification(texte, exemples=exemples_few_shot[:3])\n",
        "    resultats[\"three_shot\"].append(res_three)\n",
        "    print(f\"  Three-Shot : {res_three}\")\n",
        "\n",
        "    # Five-Shot\n",
        "    res_five = few_shot_classification(texte, exemples=exemples_few_shot)\n",
        "    resultats[\"five_shot\"].append(res_five)\n",
        "    print(f\"  Five-Shot  : {res_five}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "736dbe12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "736dbe12",
        "outputId": "231eadc5-b2b0-4995-e343-bbd857c4e971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "======================================================================\n",
            "FEW-SHOT POUR G√âN√âRATION DE FORMAT SP√âCIFIQUE\n",
            "======================================================================\n",
            "\n",
            "Sans exemples (Zero-Shot):\n",
            "### Fiche Produit : Lampe de Bureau SmartLight\n",
            "\n",
            "---\n",
            "\n",
            "**Nom du produit :** Lampe de Bureau SmartLight\n",
            "\n",
            "**Cat√©gorie :** √âclairage / Accessoires de Bureau\n",
            "\n",
            "**Description :**\n",
            "La Lampe de Bureau SmartLight allie modernit√© et fonctionnalit√© pour illuminer votre espace de travail. Gr√¢ce √† sa technologie LED avanc√©e, elle offre une exp√©rience d‚Äô√©clairage personnalis√©e, parfaite pour r√©pondre √† tous vos besoins.\n",
            "\n",
            "---\n",
            "\n",
            "#### Caract√©ristiques Principales :\n",
            "\n",
            "- **Type d'√©clairage :** LED\n",
            "- **Contr√¥le tactile :** Oui, pour un ajustement facile\n",
            "- **Niveaux de luminosit√© :** 5 niveaux (de doux √† intense)\n",
            "- **Temp√©rature de couleur :** Ajustable de 2700K (lumi√®re chaude) √† 6500K (lumi√®re froide)\n",
            "- **Consommation d'√©nergie :** 12W\n",
            "- **Port USB :** Oui, pour charger vos appareils √©lectroniques\n",
            "\n",
            "---\n",
            "\n",
            "#### Avantages :\n",
            "\n",
            "- **Personnalisation de l'√©clairage :** Adaptez la lumi√®re selon vos activit√©s (lecture, travail, d√©tente) gr√¢ce √† la temp√©rature de couleur ajustable et aux niveaux de luminosit√©.\n",
            "- **Design moderne :** Son esth√©tique √©pur√©e s'int√®gre parfaitement dans tout type de d√©cor, qu'il soit contemporain ou classique.\n",
            "- **√âconomie d'√©nergie :** Avec une consommation de seulement 12W, la SmartLight est une option √©cologique et √©conomique.\n",
            "- **Pratique et fonctionnelle :** Le port USB int√©gr√© vous permet de garder vos appareils charg√©s tout en travaillant.\n",
            "\n",
            "---\n",
            "\n",
            "#### Id√©ale pour :\n",
            "\n",
            "- **Bureaux √† domicile**\n",
            "- **Espaces de coworking**\n",
            "- **√âtudiants**\n",
            "- **Passionn√©s de lecture**\n",
            "\n",
            "---\n",
            "\n",
            "#### Dimensions :\n",
            "\n",
            "- **Hauteur :** 40 cm\n",
            "- **Largeur :** 15 cm\n",
            "- **Profondeur :** 20 cm\n",
            "- **Poids :** 1.2 kg\n",
            "\n",
            "---\n",
            "\n",
            "#### Informations suppl√©mentaires :\n",
            "\n",
            "- **Mat√©riaux :** Plastique ABS de haute qualit√©\n",
            "- **Alimentation :** Secteur (c√¢ble inclus)\n",
            "- **Garantie :** 2 ans\n",
            "\n",
            "---\n",
            "\n",
            "#### Prix : \n",
            "**29,99 ‚Ç¨**\n",
            "\n",
            "---\n",
            "\n",
            "#### Commandez Maintenant :\n",
            "Ne manquez pas l‚Äôopportunit√© de transformer votre espace de travail avec la Lampe de Bureau SmartLight. Commandez d√®s aujourd'hui et profitez d‚Äôun √©clairage sur mesure pour une productivit√© optimale !\n",
            "\n",
            "---\n",
            "\n",
            "**Contact :** Pour toute question ou assistance, veuillez nous contacter √† support@smartlight.com\n",
            "\n",
            "**Suivez-nous sur les r√©seaux sociaux :** [Facebook] [Instagram] [Twitter]\n",
            "\n",
            "--- \n",
            "\n",
            "*Cette fiche produit est con√ßue pour attirer l‚Äôattention des clients tout en fournissant les informations essentielles sur le produit.*\n",
            "\n",
            "Avec exemples (Few-Shot):\n",
            "---\n",
            "\n",
            "**Nom:** Lampe de Bureau SmartLight  \n",
            "**Tagline:** √âclairez votre cr√©ativit√© avec style  \n",
            "**Points cl√©s:**  \n",
            "‚Ä¢ Contr√¥le tactile intuitif  \n",
            "‚Ä¢ 5 niveaux de luminosit√© pour un √©clairage personnalis√©  \n",
            "‚Ä¢ Temp√©rature de couleur ajustable de 2700K √† 6500K  \n",
            "‚Ä¢ Port USB int√©gr√© pour charger vos appareils  \n",
            "‚Ä¢ Consommation √©nerg√©tique de seulement 12W  \n",
            "**Prix:** 59,99‚Ç¨  \n",
            "**Note:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (4.7/5)  \n",
            "\n",
            "---\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Exercice 4.2 : Few-Shot pour la g√©n√©ration de format sp√©cifique\n",
        "print(\"\\n\\n\" + \"=\"*70)\n",
        "print(\"FEW-SHOT POUR G√âN√âRATION DE FORMAT SP√âCIFIQUE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "def generer_fiche_produit(nom_produit: str, description: str, exemples: list = None):\n",
        "    \"\"\"\n",
        "    G√©n√®re une fiche produit structur√©e en utilisant le few-shot learning.\n",
        "    \"\"\"\n",
        "    system_prompt = \"Tu es un r√©dacteur marketing expert.\"\n",
        "\n",
        "    user_prompt = \"G√©n√®re une fiche produit structur√©e.\\n\\n\"\n",
        "\n",
        "    if exemples:\n",
        "        user_prompt += \"Exemples de fiches produits :\\n\\n\"\n",
        "        for ex in exemples:\n",
        "            user_prompt += f\"---\\n{ex}\\n---\\n\\n\"\n",
        "\n",
        "    user_prompt += f\"\"\"\n",
        "Produit: {nom_produit}\n",
        "Description brute: {description}\n",
        "\n",
        "G√©n√®re la fiche produit:\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "# Exemples de fiches produits pour le few-shot\n",
        "# üí° Personnalisez selon votre secteur d'activit√©\n",
        "exemples_fiches = [\n",
        "    \"\"\"\n",
        "**Nom:** Casque Audio ProSound X1\n",
        "**Tagline:** L'excellence sonore √† port√©e d'oreilles\n",
        "**Points cl√©s:**\n",
        "‚Ä¢ R√©duction de bruit active -40dB\n",
        "‚Ä¢ Autonomie 30 heures\n",
        "‚Ä¢ Bluetooth 5.3\n",
        "**Prix:** 149,99‚Ç¨\n",
        "**Note:** ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (4.8/5)\n",
        "\"\"\",\n",
        "    \"\"\"\n",
        "**Nom:** Montre Connect√©e FitPulse\n",
        "**Tagline:** Votre sant√© au poignet\n",
        "**Points cl√©s:**\n",
        "‚Ä¢ Suivi cardiaque 24/7\n",
        "‚Ä¢ GPS int√©gr√©\n",
        "‚Ä¢ √âtanche 50m\n",
        "**Prix:** 199,99‚Ç¨\n",
        "**Note:** ‚≠ê‚≠ê‚≠ê‚≠ê (4.5/5)\n",
        "\"\"\"\n",
        "]\n",
        "\n",
        "# Test avec et sans exemples\n",
        "produit_test = {\n",
        "    \"nom\": \"Lampe de Bureau SmartLight\",\n",
        "    \"description\": \"lampe LED avec contr√¥le tactile, 5 niveaux de luminosit√©, port USB, temp√©rature de couleur ajustable 2700K-6500K, consommation 12W\"\n",
        "}\n",
        "\n",
        "print(\"\\nSans exemples (Zero-Shot):\")\n",
        "print(generer_fiche_produit(produit_test[\"nom\"], produit_test[\"description\"]))\n",
        "\n",
        "print(\"\\nAvec exemples (Few-Shot):\")\n",
        "print(generer_fiche_produit(produit_test[\"nom\"], produit_test[\"description\"], exemples_fiches))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e33ffb6",
      "metadata": {
        "id": "3e33ffb6"
      },
      "source": [
        "---\n",
        "\n",
        "## Partie 5 : Chain of Thought (CoT)\n",
        "\n",
        "### Raisonnement √âtape par √âtape\n",
        "\n",
        "Le **Chain of Thought** encourage le mod√®le √† expliciter son raisonnement avant de donner une r√©ponse finale. Cette technique am√©liore significativement les performances sur les t√¢ches de raisonnement complexe.\n",
        "\n",
        "**Variantes :**\n",
        "- **Zero-Shot CoT** : Ajouter \"R√©fl√©chissons √©tape par √©tape\" au prompt\n",
        "- **Few-Shot CoT** : Fournir des exemples avec raisonnement d√©taill√©\n",
        "- **Self-Consistency** : G√©n√©rer plusieurs raisonnements et voter\n",
        "\n",
        "### Pratique : Impl√©mentation du CoT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "eG2EtWcheMTV",
      "metadata": {
        "id": "eG2EtWcheMTV"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Exercice 5 : Chain of Thought Prompting\n",
        "Objectif : Am√©liorer les capacit√©s de raisonnement du LLM\n",
        "\"\"\"\n",
        "\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def resoudre_probleme(probleme: str, methode: str = \"direct\", model: str = \"gpt-4o-mini\"):\n",
        "    \"\"\"\n",
        "    R√©sout un probl√®me avec diff√©rentes m√©thodes de prompting.\n",
        "\n",
        "    Args:\n",
        "        probleme: Le probl√®me √† r√©soudre\n",
        "        methode: \"direct\", \"zero_shot_cot\", \"few_shot_cot\"\n",
        "        model: Mod√®le √† utiliser\n",
        "    \"\"\"\n",
        "\n",
        "    if methode == \"direct\":\n",
        "        # R√©ponse directe sans raisonnement\n",
        "        prompt = f\"{probleme}\\n\\nR√©ponds directement avec la r√©ponse.\"\n",
        "\n",
        "    elif methode == \"zero_shot_cot\":\n",
        "        # Zero-shot Chain of Thought\n",
        "        prompt = f\"\"\"{probleme}\n",
        "\n",
        "        R√©fl√©chissons √©tape par √©tape.\n",
        "        1. Identifie les informations cl√©s\n",
        "        2. √âtablis les relations entre elles\n",
        "        3. Effectue les calculs n√©cessaires\n",
        "        4. V√©rifie ta r√©ponse\n",
        "\n",
        "        Raisonnement:\"\"\"\n",
        "\n",
        "    elif methode == \"few_shot_cot\":\n",
        "        # Few-shot Chain of Thought avec exemples\n",
        "        prompt = f\"\"\"Voici comment r√©soudre des probl√®mes de logique √©tape par √©tape :\n",
        "\n",
        "        **Exemple 1:**\n",
        "        Probl√®me: Marie a 3 pommes. Elle en donne la moiti√© √† Paul, puis ach√®te 4 pommes. Combien a-t-elle de pommes ?\n",
        "\n",
        "        Raisonnement:\n",
        "        1. Marie commence avec 3 pommes\n",
        "        2. Elle donne la moiti√© √† Paul : 3 √∑ 2 = 1.5, mais on ne peut pas couper une pomme, donc elle donne 1 pomme (ou 2 si on arrondit au sup√©rieur). Supposons qu'elle donne 1 pomme.\n",
        "        3. Apr√®s avoir donn√© : 3 - 1 = 2 pommes\n",
        "        4. Elle ach√®te 4 pommes : 2 + 4 = 6 pommes\n",
        "\n",
        "        R√©ponse: Marie a 6 pommes.\n",
        "\n",
        "        **Exemple 2:**\n",
        "        Probl√®me: Un train part de Paris √† 8h et arrive √† Lyon √† 10h. Un autre train part de Lyon √† 9h et arrive √† Paris √† 11h. √Ä quelle heure les trains se croisent-ils ?\n",
        "\n",
        "        Raisonnement:\n",
        "        1. Train 1 : Paris‚ÜíLyon, d√©part 8h, arriv√©e 10h, dur√©e = 2h\n",
        "        2. Train 2 : Lyon‚ÜíParis, d√©part 9h, arriv√©e 11h, dur√©e = 2h\n",
        "        3. Distance = D. Vitesse train 1 = D/2. Vitesse train 2 = D/2.\n",
        "        4. √Ä 9h, train 1 a parcouru 1h, donc D/2 de distance.\n",
        "        5. Train 1 est √† mi-chemin, train 2 part.\n",
        "        6. Ils se rapprochent √† vitesse D/2 + D/2 = D par heure.\n",
        "        7. Distance restante = D/2. Temps = (D/2) / D = 0.5h = 30 min.\n",
        "        8. Croisement : 9h + 30min = 9h30\n",
        "\n",
        "        R√©ponse: Les trains se croisent √† 9h30.\n",
        "\n",
        "        ---\n",
        "\n",
        "        **Nouveau probl√®me:**\n",
        "        {probleme}\n",
        "\n",
        "        Raisonnement:\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        temperature=0.3,\n",
        "        max_tokens=1000\n",
        "    )\n",
        "\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "3wY71b-veYVJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3wY71b-veYVJ",
        "outputId": "0a523ea9-44fb-4df6-9554-990db94a8131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "COMPARAISON DES M√âTHODES DE RAISONNEMENT\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "PROBL√àME 1\n",
            "======================================================================\n",
            "Dans une entreprise de 120 employ√©s, 40% travaillent au d√©partement marketing, \n",
            "    25% au d√©partement technique, et le reste au d√©partement administratif.\n",
            "    Le d√©partement marketing a re√ßu une prime de 500‚Ç¨ par employ√©.\n",
            "    Le d√©partement technique a re√ßu une prime de 750‚Ç¨ par employ√©.\n",
            "    Le d√©partement administratif a re√ßu une prime de 400‚Ç¨ par employ√©.\n",
            "    Quel est le montant total des primes distribu√©es ?\n",
            "\n",
            "-----------------------------------\n",
            "M√©thode DIRECTE:\n",
            "-----------------------------------\n",
            "Le montant total des primes distribu√©es est de 62 500 ‚Ç¨.\n",
            "\n",
            "-----------------------------------\n",
            "M√©thode ZERO-SHOT CoT:\n",
            "-----------------------------------\n",
            "Pour r√©soudre le probl√®me, suivons les √©tapes que vous avez indiqu√©es.\n",
            "\n",
            "### 1. Identifie les informations cl√©s\n",
            "- Total des employ√©s : 120\n",
            "- Pourcentage d'employ√©s au d√©partement marketing : 40%\n",
            "- Pourcentage d'employ√©s au d√©partement technique : 25%\n",
            "- Pourcentage d'employ√©s au d√©partement administratif : 100% - 40% - 25% = 35%\n",
            "- Prime par employ√© :\n",
            "  - Marketing : 500‚Ç¨\n",
            "  - Technique : 750‚Ç¨\n",
            "  - Administratif : 400‚Ç¨\n",
            "\n",
            "### 2. √âtablis les relations entre elles\n",
            "Nous devons d'abord d√©terminer le nombre d'employ√©s dans chaque d√©partement, puis calculer le montant total des primes distribu√©es √† chaque d√©partement.\n",
            "\n",
            "### 3. Effectue les calculs n√©cessaires\n",
            "**Calcul du nombre d'employ√©s par d√©partement :**\n",
            "- Employ√©s au d√©partement marketing : \n",
            "  \\[\n",
            "  120 \\times 0.40 = 48\n",
            "  \\]\n",
            "  \n",
            "- Employ√©s au d√©partement technique : \n",
            "  \\[\n",
            "  120 \\times 0.25 = 30\n",
            "  \\]\n",
            "  \n",
            "- Employ√©s au d√©partement administratif : \n",
            "  \\[\n",
            "  120 \\times 0.35 = 42\n",
            "  \\]\n",
            "\n",
            "**Calcul des primes distribu√©es par d√©partement :**\n",
            "- Total des primes pour le d√©partement marketing : \n",
            "  \\[\n",
            "  48 \\times 500 = 24000‚Ç¨\n",
            "  \\]\n",
            "\n",
            "- Total des primes pour le d√©partement technique : \n",
            "  \\[\n",
            "  30 \\times 750 = 22500‚Ç¨\n",
            "  \\]\n",
            "\n",
            "- Total des primes pour le d√©partement administratif : \n",
            "  \\[\n",
            "  42 \\times 400 = 16800‚Ç¨\n",
            "  \\]\n",
            "\n",
            "**Montant total des primes distribu√©es :**\n",
            "\\[\n",
            "24000 + 22500 + 16800 = 63300‚Ç¨\n",
            "\\]\n",
            "\n",
            "### 4. V√©rifie ta r√©ponse\n",
            "- Employ√©s marketing : 48, primes : 24000‚Ç¨\n",
            "- Employ√©s technique : 30, primes : 22500‚Ç¨\n",
            "- Employ√©s administratif : 42, primes : 16800‚Ç¨\n",
            "- Total des primes : 24000 + 22500 + 16800 = 63300‚Ç¨\n",
            "\n",
            "La r√©ponse est correcte.\n",
            "\n",
            "### Conclusion\n",
            "Le montant total des primes distribu√©es est de **63300‚Ç¨**.\n",
            "\n",
            "-----------------------------------\n",
            "M√©thode FEW-SHOT CoT:\n",
            "-----------------------------------\n",
            "Pour r√©soudre ce probl√®me √©tape par √©tape, nous allons d'abord d√©terminer le nombre d'employ√©s dans chaque d√©partement, puis calculer le montant total des primes distribu√©es.\n",
            "\n",
            "1. **Total des employ√©s** : 120 employ√©s.\n",
            "\n",
            "2. **Calcul du nombre d'employ√©s par d√©partement** :\n",
            "   - **D√©partement marketing** : 40% de 120\n",
            "     \\[\n",
            "     0.40 \\times 120 = 48 \\text{ employ√©s}\n",
            "     \\]\n",
            "   - **D√©partement technique** : 25% de 120\n",
            "     \\[\n",
            "     0.25 \\times 120 = 30 \\text{ employ√©s}\n",
            "     \\]\n",
            "   - **D√©partement administratif** : Le reste des employ√©s\n",
            "     \\[\n",
            "     120 - (48 + 30) = 120 - 78 = 42 \\text{ employ√©s}\n",
            "     \\]\n",
            "\n",
            "3. **Calcul des primes par d√©partement** :\n",
            "   - **Prime pour le d√©partement marketing** : 500‚Ç¨ par employ√©\n",
            "     \\[\n",
            "     48 \\times 500 = 24000 \\text{ ‚Ç¨}\n",
            "     \\]\n",
            "   - **Prime pour le d√©partement technique** : 750‚Ç¨ par employ√©\n",
            "     \\[\n",
            "     30 \\times 750 = 22500 \\text{ ‚Ç¨}\n",
            "     \\]\n",
            "   - **Prime pour le d√©partement administratif** : 400‚Ç¨ par employ√©\n",
            "     \\[\n",
            "     42 \\times 400 = 16800 \\text{ ‚Ç¨}\n",
            "     \\]\n",
            "\n",
            "4. **Calcul du montant total des primes distribu√©es** :\n",
            "   \\[\n",
            "   24000 + 22500 + 16800 = 63300 \\text{ ‚Ç¨}\n",
            "   \\]\n",
            "\n",
            "**R√©ponse** : Le montant total des primes distribu√©es est de 63300 ‚Ç¨.\n",
            "\n",
            "======================================================================\n",
            "PROBL√àME 2\n",
            "======================================================================\n",
            "Alice, Bob et Charlie participent √† une course. Alice termine avant Bob.\n",
            "    Charlie ne termine pas dernier. Bob termine apr√®s Charlie.\n",
            "    Dans quel ordre ont-ils termin√© la course ?\n",
            "\n",
            "-----------------------------------\n",
            "M√©thode DIRECTE:\n",
            "-----------------------------------\n",
            "L'ordre dans lequel ils ont termin√© la course est : Alice, Charlie, Bob.\n",
            "\n",
            "-----------------------------------\n",
            "M√©thode ZERO-SHOT CoT:\n",
            "-----------------------------------\n",
            "Pour r√©soudre ce probl√®me, proc√©dons √©tape par √©tape.\n",
            "\n",
            "### 1. Identifie les informations cl√©s\n",
            "- Alice termine avant Bob.\n",
            "- Charlie ne termine pas dernier.\n",
            "- Bob termine apr√®s Charlie.\n",
            "\n",
            "### 2. √âtablis les relations entre elles\n",
            "- Puisqu'Alice termine avant Bob, nous avons : Alice > Bob.\n",
            "- Charlie ne termine pas dernier, ce qui signifie qu'il termine soit premier, soit deuxi√®me.\n",
            "- Bob termine apr√®s Charlie, donc nous avons : Charlie > Bob.\n",
            "\n",
            "### 3. Effectue les calculs n√©cessaires\n",
            "En combinant les informations :\n",
            "- Si Alice > Bob et Charlie > Bob, cela signifie que Charlie doit √™tre soit premier, soit deuxi√®me.\n",
            "- Si Charlie est premier, alors Alice doit √™tre deuxi√®me et Bob doit √™tre dernier. Cela donnerait l'ordre : Charlie > Alice > Bob.\n",
            "- Si Charlie est deuxi√®me, alors Alice doit √™tre premi√®re, et Bob doit √™tre dernier. Cela donnerait l'ordre : Alice > Charlie > Bob.\n",
            "\n",
            "Cependant, la premi√®re option (Charlie > Alice > Bob) ne respecte pas la condition \"Alice termine avant Bob\", car Alice est d√©j√† avant Bob dans les deux options. \n",
            "\n",
            "### 4. V√©rifie ta r√©ponse\n",
            "En examinant les deux options :\n",
            "1. **Charlie > Alice > Bob** : Cela respecte toutes les conditions.\n",
            "2. **Alice > Charlie > Bob** : Cela respecte aussi toutes les conditions.\n",
            "\n",
            "En conclusion, l'ordre final qui respecte toutes les conditions est :\n",
            "1. **Alice**\n",
            "2. **Charlie**\n",
            "3. **Bob**\n",
            "\n",
            "Donc, l'ordre dans lequel ils ont termin√© la course est : **Alice, Charlie, Bob**.\n",
            "\n",
            "-----------------------------------\n",
            "M√©thode FEW-SHOT CoT:\n",
            "-----------------------------------\n",
            "Pour r√©soudre le probl√®me concernant l'ordre d'arriv√©e d'Alice, Bob et Charlie dans la course, proc√©dons √©tape par √©tape :\n",
            "\n",
            "1. **Informations donn√©es :**\n",
            "   - Alice termine avant Bob.\n",
            "   - Charlie ne termine pas dernier.\n",
            "   - Bob termine apr√®s Charlie.\n",
            "\n",
            "2. **Analysons les informations :**\n",
            "   - Puisque Alice termine avant Bob, cela signifie qu'Alice est soit premi√®re, soit deuxi√®me.\n",
            "   - Charlie ne termine pas dernier, ce qui signifie qu'il doit √™tre soit premier, soit deuxi√®me.\n",
            "   - Bob termine apr√®s Charlie, ce qui signifie que Bob doit √™tre soit deuxi√®me, soit troisi√®me.\n",
            "\n",
            "3. **D√©ductions :**\n",
            "   - Si Alice est premi√®re, alors Charlie doit √™tre deuxi√®me (puisqu'il ne peut pas √™tre dernier) et Bob serait troisi√®me. Cela respecte toutes les conditions : \n",
            "     - Alice (1√®re) avant Bob (3√®me).\n",
            "     - Charlie (2√®me) ne termine pas dernier.\n",
            "     - Bob (3√®me) termine apr√®s Charlie (2√®me).\n",
            "   - Si Alice est deuxi√®me, alors Charlie doit √™tre premier (pour ne pas √™tre dernier), mais cela contredirait le fait que Bob termine apr√®s Charlie, car cela impliquerait que Bob serait dernier. Donc, Alice ne peut pas √™tre deuxi√®me.\n",
            "\n",
            "4. **Conclusion :**\n",
            "   - L'unique ordre qui respecte toutes les conditions est :\n",
            "     - Alice termine 1√®re,\n",
            "     - Charlie termine 2√®me,\n",
            "     - Bob termine 3√®me.\n",
            "\n",
            "**R√©ponse :** L'ordre d'arriv√©e est : Alice, Charlie, Bob.\n",
            "\n",
            "======================================================================\n",
            "PROBL√àME 3\n",
            "======================================================================\n",
            "Un fermier a des poules et des lapins dans sa ferme.\n",
            "    Il compte 20 t√™tes et 56 pattes au total.\n",
            "    Combien a-t-il de poules et combien a-t-il de lapins ?\n",
            "\n",
            "-----------------------------------\n",
            "M√©thode DIRECTE:\n",
            "-----------------------------------\n",
            "Le fermier a 12 poules et 8 lapins.\n",
            "\n",
            "-----------------------------------\n",
            "M√©thode ZERO-SHOT CoT:\n",
            "-----------------------------------\n",
            "Pour r√©soudre ce probl√®me, nous allons suivre les √©tapes que vous avez indiqu√©es.\n",
            "\n",
            "### 1. Identifie les informations cl√©s\n",
            "- Le fermier a un total de 20 t√™tes (poules + lapins).\n",
            "- Le fermier a un total de 56 pattes.\n",
            "- Chaque poule a 1 t√™te et 2 pattes.\n",
            "- Chaque lapin a 1 t√™te et 4 pattes.\n",
            "\n",
            "### 2. √âtablis les relations entre elles\n",
            "Posons les variables suivantes :\n",
            "- \\( P \\) = nombre de poules\n",
            "- \\( L \\) = nombre de lapins\n",
            "\n",
            "Nous avons deux √©quations bas√©es sur les informations fournies :\n",
            "1. Pour le nombre de t√™tes : \n",
            "   \\[\n",
            "   P + L = 20\n",
            "   \\]\n",
            "2. Pour le nombre de pattes :\n",
            "   \\[\n",
            "   2P + 4L = 56\n",
            "   \\]\n",
            "\n",
            "### 3. Effectue les calculs n√©cessaires\n",
            "Nous allons r√©soudre ce syst√®me d'√©quations. \n",
            "\n",
            "√Ä partir de la premi√®re √©quation, nous pouvons exprimer \\( L \\) en fonction de \\( P \\) :\n",
            "\\[\n",
            "L = 20 - P\n",
            "\\]\n",
            "\n",
            "Nous substituons cette expression dans la deuxi√®me √©quation :\n",
            "\\[\n",
            "2P + 4(20 - P) = 56\n",
            "\\]\n",
            "\n",
            "D√©veloppons cette √©quation :\n",
            "\\[\n",
            "2P + 80 - 4P = 56\n",
            "\\]\n",
            "\n",
            "Regroupons les termes :\n",
            "\\[\n",
            "-2P + 80 = 56\n",
            "\\]\n",
            "\n",
            "Soustrayons 80 des deux c√¥t√©s :\n",
            "\\[\n",
            "-2P = 56 - 80\n",
            "\\]\n",
            "\\[\n",
            "-2P = -24\n",
            "\\]\n",
            "\n",
            "Divisons par -2 :\n",
            "\\[\n",
            "P = 12\n",
            "\\]\n",
            "\n",
            "Maintenant, substituons \\( P \\) dans l'√©quation pour \\( L \\) :\n",
            "\\[\n",
            "L = 20 - P = 20 - 12 = 8\n",
            "\\]\n",
            "\n",
            "### 4. V√©rifie ta r√©ponse\n",
            "Nous avons trouv√© :\n",
            "- \\( P = 12 \\) (poules)\n",
            "- \\( L = 8 \\) (lapins)\n",
            "\n",
            "V√©rifions les conditions :\n",
            "- Nombre total de t√™tes : \\( 12 + 8 = 20 \\) (correct)\n",
            "- Nombre total de pattes : \\( 2 \\times 12 + 4 \\times 8 = 24 + 32 = 56 \\) (correct)\n",
            "\n",
            "### Conclusion\n",
            "Le fermier a donc **12 poules** et **8 lapins**.\n",
            "\n",
            "-----------------------------------\n",
            "M√©thode FEW-SHOT CoT:\n",
            "-----------------------------------\n",
            "Pour r√©soudre le probl√®me des poules et des lapins, nous allons utiliser un syst√®me d'√©quations. Voici les √©tapes :\n",
            "\n",
            "1. **D√©finir les variables** :\n",
            "   - Soit \\( p \\) le nombre de poules.\n",
            "   - Soit \\( l \\) le nombre de lapins.\n",
            "\n",
            "2. **√âtablir les √©quations** :\n",
            "   - Chaque animal a une t√™te, donc le nombre total de t√™tes est donn√© par l'√©quation :\n",
            "     \\[\n",
            "     p + l = 20 \\quad \\text{(1)}\n",
            "     \\]\n",
            "   - Les poules ont 2 pattes et les lapins en ont 4, donc le nombre total de pattes est donn√© par l'√©quation :\n",
            "     \\[\n",
            "     2p + 4l = 56 \\quad \\text{(2)}\n",
            "     \\]\n",
            "\n",
            "3. **Simplifier l'√©quation des pattes** :\n",
            "   - Divisons l'√©quation (2) par 2 pour simplifier :\n",
            "     \\[\n",
            "     p + 2l = 28 \\quad \\text{(3)}\n",
            "     \\]\n",
            "\n",
            "4. **R√©soudre le syst√®me d'√©quations** :\n",
            "   - Nous avons maintenant le syst√®me :\n",
            "     \\[\n",
            "     \\begin{cases}\n",
            "     p + l = 20 \\quad \\text{(1)} \\\\\n",
            "     p + 2l = 28 \\quad \\text{(3)}\n",
            "     \\end{cases}\n",
            "     \\]\n",
            "   - Soustrayons l'√©quation (1) de l'√©quation (3) :\n",
            "     \\[\n",
            "     (p + 2l) - (p + l) = 28 - 20\n",
            "     \\]\n",
            "     \\[\n",
            "     l = 8\n",
            "     \\]\n",
            "\n",
            "5. **Trouver le nombre de poules** :\n",
            "   - En substituant \\( l = 8 \\) dans l'√©quation (1) :\n",
            "     \\[\n",
            "     p + 8 = 20\n",
            "     \\]\n",
            "     \\[\n",
            "     p = 20 - 8 = 12\n",
            "     \\]\n",
            "\n",
            "6. **Conclusion** :\n",
            "   - Le fermier a donc 12 poules et 8 lapins.\n",
            "\n",
            "**R√©ponse**: Le fermier a 12 poules et 8 lapins.\n"
          ]
        }
      ],
      "source": [
        "# Probl√®mes de test\n",
        "# Ajoutez vos propres probl√®mes\n",
        "problemes = [\n",
        "    \"\"\"\n",
        "    Dans une entreprise de 120 employ√©s, 40% travaillent au d√©partement marketing,\n",
        "    25% au d√©partement technique, et le reste au d√©partement administratif.\n",
        "    Le d√©partement marketing a re√ßu une prime de 500‚Ç¨ par employ√©.\n",
        "    Le d√©partement technique a re√ßu une prime de 750‚Ç¨ par employ√©.\n",
        "    Le d√©partement administratif a re√ßu une prime de 400‚Ç¨ par employ√©.\n",
        "    Quel est le montant total des primes distribu√©es ?\n",
        "    \"\"\",\n",
        "    #\"\"\"\n",
        "    #Alice, Bob et Charlie participent √† une course. Alice termine avant Bob.\n",
        "    #Charlie ne termine pas dernier. Bob termine apr√®s Charlie.\n",
        "    #Dans quel ordre ont-ils termin√© la course ?\n",
        "    #\"\"\",\n",
        "    #\"\"\"\n",
        "    #Un fermier a des poules et des lapins dans sa ferme.\n",
        "    #Il compte 20 t√™tes et 56 pattes au total.\n",
        "    #Combien a-t-il de poules et combien a-t-il de lapins ?\n",
        "    #\"\"\"\n",
        "]\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"COMPARAISON DES M√âTHODES DE RAISONNEMENT\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for i, probleme in enumerate(problemes, 1):\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"PROBL√àME {i}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(probleme.strip())\n",
        "\n",
        "    print(\"\\n\" + \"-\"*35)\n",
        "    print(\"M√©thode DIRECTE:\")\n",
        "    print(\"-\"*35)\n",
        "    print(resoudre_probleme(probleme, methode=\"direct\"))\n",
        "\n",
        "    print(\"\\n\" + \"-\"*35)\n",
        "    print(\"M√©thode ZERO-SHOT CoT:\")\n",
        "    print(\"-\"*35)\n",
        "    print(resoudre_probleme(probleme, methode=\"zero_shot_cot\"))\n",
        "\n",
        "    print(\"\\n\" + \"-\"*35)\n",
        "    print(\"M√©thode FEW-SHOT CoT:\")\n",
        "    print(\"-\"*35)\n",
        "    print(resoudre_probleme(probleme, methode=\"few_shot_cot\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91ddb97c",
      "metadata": {
        "id": "91ddb97c"
      },
      "source": [
        "---\n",
        "\n",
        "## Partie 6 : ReAct Prompting\n",
        "\n",
        "### Raisonnement et Action\n",
        "\n",
        "**ReAct** (Reasoning + Acting) combine le raisonnement explicite avec l'ex√©cution d'actions. Le mod√®le alterne entre :\n",
        "- **Thought** (Pens√©e) : R√©flexion sur la situation\n",
        "- **Action** : Ex√©cution d'une action (recherche, calcul, etc.)\n",
        "- **Observation** : R√©sultat de l'action\n",
        "\n",
        "### Pratique : Impl√©mentation de ReAct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "6H2yRhqufIfN",
      "metadata": {
        "id": "6H2yRhqufIfN"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Exercice 6 : ReAct Prompting\n",
        "Objectif : Combiner raisonnement et actions pour des t√¢ches complexes\n",
        "\"\"\"\n",
        "\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "class ReactAgent:\n",
        "    \"\"\"\n",
        "    Agent ReAct simplifi√© avec des outils simul√©s.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: str = \"gpt-4o-mini\"):\n",
        "        self.model = model\n",
        "        self.historique = []\n",
        "        self.outils = {\n",
        "            \"recherche\": self._recherche,\n",
        "            \"calcul\": self._calcul,\n",
        "            \"date\": self._date,\n",
        "        }\n",
        "\n",
        "    def _recherche(self, query: str) -> str:\n",
        "        \"\"\"Simule une recherche (√† remplacer par une vraie API).\"\"\"\n",
        "        # Personnalisez avec une vraie API de recherche\n",
        "        base_connaissances = {\n",
        "            \"capitale france\": \"La capitale de la France est Paris.\",\n",
        "            \"population paris\": \"Paris compte environ 2,1 millions d'habitants (ville) et 12 millions (agglom√©ration).\",\n",
        "            \"tour eiffel hauteur\": \"La Tour Eiffel mesure 330 m√®tres avec son antenne.\",\n",
        "            \"python cr√©ateur\": \"Python a √©t√© cr√©√© par Guido van Rossum en 1991.\",\n",
        "            \"openai fondation\": \"OpenAI a √©t√© fond√©e en 2015 par Sam Altman, Elon Musk et d'autres.\",\n",
        "        }\n",
        "\n",
        "        query_lower = query.lower()\n",
        "        for cle, valeur in base_connaissances.items():\n",
        "            if any(mot in query_lower for mot in cle.split()):\n",
        "                return valeur\n",
        "\n",
        "        return f\"Aucune information trouv√©e pour: {query}\"\n",
        "\n",
        "    def _calcul(self, expression: str) -> str:\n",
        "        \"\"\"Effectue un calcul math√©matique.\"\"\"\n",
        "        try:\n",
        "            # Nettoyage de l'expression\n",
        "            expression_clean = expression.replace(\"^\", \"**\").replace(\"√ó\", \"*\").replace(\"√∑\", \"/\")\n",
        "            resultat = eval(expression_clean)\n",
        "            return f\"R√©sultat: {resultat}\"\n",
        "        except Exception as e:\n",
        "            return f\"Erreur de calcul: {e}\"\n",
        "\n",
        "    def _date(self, query: str) -> str:\n",
        "        \"\"\"Retourne la date actuelle.\"\"\"\n",
        "        from datetime import datetime\n",
        "        return f\"Date actuelle: {datetime.now().strftime('%d/%m/%Y %H:%M')}\"\n",
        "\n",
        "    def executer_action(self, action: str, parametre: str) -> str:\n",
        "        \"\"\"Ex√©cute une action et retourne l'observation.\"\"\"\n",
        "        action = action.lower().strip()\n",
        "        if action in self.outils:\n",
        "            return self.outils[action](parametre)\n",
        "        return f\"Action inconnue: {action}. Actions disponibles: {list(self.outils.keys())}\"\n",
        "\n",
        "    def resoudre(self, question: str, max_iterations: int = 5) -> str:\n",
        "        \"\"\"\n",
        "        R√©sout une question en utilisant le pattern ReAct.\n",
        "        \"\"\"\n",
        "        system_prompt = \"\"\"Tu es un assistant qui r√©sout des probl√®mes en utilisant le pattern ReAct.\n",
        "\n",
        "        √Ä chaque √©tape, tu dois:\n",
        "        1. THOUGHT: R√©fl√©chir √† ce que tu sais et ce que tu dois faire\n",
        "        2. ACTION: Choisir une action parmi [recherche, calcul, date]\n",
        "        3. Attendre l'OBSERVATION\n",
        "\n",
        "        Format de r√©ponse pour chaque √©tape:\n",
        "        THOUGHT: [ta r√©flexion]\n",
        "        ACTION: [nom_action]\n",
        "        INPUT: [param√®tre de l'action]\n",
        "\n",
        "        Quand tu as la r√©ponse finale, √©cris:\n",
        "        THOUGHT: [r√©flexion finale]\n",
        "        FINAL_ANSWER: [ta r√©ponse compl√®te]\n",
        "\n",
        "        Actions disponibles:\n",
        "        - recherche: Recherche d'information (INPUT: mots-cl√©s)\n",
        "        - calcul: Calcul math√©matique (INPUT: expression math√©matique)\n",
        "        - date: Obtenir la date actuelle (INPUT: vide)\"\"\"\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": f\"Question: {question}\"}\n",
        "        ]\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Question: {question}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        for iteration in range(max_iterations):\n",
        "            print(f\"\\n--- It√©ration {iteration + 1} ---\")\n",
        "\n",
        "            # Obtenir la prochaine √©tape du mod√®le\n",
        "            response = client.chat.completions.create(\n",
        "                model=self.model,\n",
        "                messages=messages,\n",
        "                temperature=0.3,\n",
        "                max_tokens=500\n",
        "            )\n",
        "\n",
        "            reponse_texte = response.choices[0].message.content\n",
        "            print(f\"\\nMod√®le:\\n{reponse_texte}\")\n",
        "\n",
        "            # V√©rifier si on a une r√©ponse finale\n",
        "            if \"FINAL_ANSWER:\" in reponse_texte:\n",
        "                final = reponse_texte.split(\"FINAL_ANSWER:\")[-1].strip()\n",
        "                print(f\"\\nR√©ponse finale: {final}\")\n",
        "                return final\n",
        "\n",
        "            # Parser l'action\n",
        "            action_match = re.search(r\"ACTION:\\s*(\\w+)\", reponse_texte)\n",
        "            input_match = re.search(r\"INPUT:\\s*(.+?)(?:\\n|$)\", reponse_texte)\n",
        "\n",
        "            if action_match:\n",
        "                action = action_match.group(1)\n",
        "                parametre = input_match.group(1) if input_match else \"\"\n",
        "\n",
        "                # Ex√©cuter l'action\n",
        "                observation = self.executer_action(action, parametre)\n",
        "                print(f\"\\nObservation: {observation}\")\n",
        "\n",
        "                # Ajouter au contexte\n",
        "                messages.append({\"role\": \"assistant\", \"content\": reponse_texte})\n",
        "                messages.append({\"role\": \"user\", \"content\": f\"OBSERVATION: {observation}\"})\n",
        "            else:\n",
        "                print(\"Aucune action d√©tect√©e, ajout au contexte...\")\n",
        "                messages.append({\"role\": \"assistant\", \"content\": reponse_texte})\n",
        "\n",
        "        return \"Nombre maximum d'it√©rations atteint.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "BbP8xAJxfYHe",
      "metadata": {
        "id": "BbP8xAJxfYHe"
      },
      "outputs": [],
      "source": [
        "# Cr√©ation de l'agent\n",
        "agent = ReactAgent()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "v6d1W5XSfo0g",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6d1W5XSfo0g",
        "outputId": "1cd71b14-5dfe-429d-b8c4-07412f362297"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "********************\n",
            "EXERCICE 6.1 : QUESTIONS COMPLEXES\n",
            "********************\n",
            "\n",
            "============================================================\n",
            "Question: Quelle est la population de la capitale de la France ?\n",
            "============================================================\n",
            "\n",
            "--- It√©ration 1 ---\n",
            "\n",
            "Mod√®le:\n",
            "THOUGHT: Je sais que la capitale de la France est Paris, et je dois rechercher la population actuelle de cette ville. \n",
            "ACTION: recherche\n",
            "INPUT: population Paris 2023\n",
            "\n",
            "Observation: Paris compte environ 2,1 millions d'habitants (ville) et 12 millions (agglom√©ration).\n",
            "\n",
            "--- It√©ration 2 ---\n",
            "\n",
            "Mod√®le:\n",
            "THOUGHT: J'ai trouv√© que Paris a une population d'environ 2,1 millions d'habitants pour la ville elle-m√™me, et environ 12 millions pour l'agglom√©ration. Je vais maintenant formuler ma r√©ponse finale. \n",
            "FINAL_ANSWER: La population de la capitale de la France, Paris, est d'environ 2,1 millions d'habitants, tandis que l'agglom√©ration parisienne compte environ 12 millions d'habitants.\n",
            "\n",
            "R√©ponse finale: La population de la capitale de la France, Paris, est d'environ 2,1 millions d'habitants, tandis que l'agglom√©ration parisienne compte environ 12 millions d'habitants.\n",
            "\n",
            "------------------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "Question: Si la Tour Eiffel mesurait 2 fois sa hauteur actuelle, combien mesurerait-elle ?\n",
            "============================================================\n",
            "\n",
            "--- It√©ration 1 ---\n",
            "\n",
            "Mod√®le:\n",
            "THOUGHT: Je sais que la hauteur actuelle de la Tour Eiffel est d'environ 330 m√®tres (y compris les antennes). Si je double cette hauteur, je pourrai donner la r√©ponse. \n",
            "ACTION: calcul \n",
            "INPUT: 330 * 2\n",
            "\n",
            "Observation: R√©sultat: 660\n",
            "\n",
            "--- It√©ration 2 ---\n",
            "\n",
            "Mod√®le:\n",
            "THOUGHT: En doublant la hauteur actuelle de la Tour Eiffel, j'ai trouv√© qu'elle mesurerait 660 m√®tres. C'est une r√©ponse directe √† la question pos√©e. \n",
            "FINAL_ANSWER: Si la Tour Eiffel mesurait 2 fois sa hauteur actuelle, elle mesurerait 660 m√®tres.\n",
            "\n",
            "R√©ponse finale: Si la Tour Eiffel mesurait 2 fois sa hauteur actuelle, elle mesurerait 660 m√®tres.\n",
            "\n",
            "------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Exercice 6.1 : Questions n√©cessitant recherche + raisonnement\n",
        "print(\"\\n\" + \"*\"*20)\n",
        "print(\"EXERCICE 6.1 : QUESTIONS COMPLEXES\")\n",
        "print(\"*\"*20)\n",
        "\n",
        "questions = [\n",
        "    \"Quelle est la population de la capitale de la France ?\",\n",
        "    \"Si la Tour Eiffel mesurait 2 fois sa hauteur actuelle, combien mesurerait-elle ?\",\n",
        "    #\"En quelle ann√©e Python a-t-il √©t√© cr√©√©, et quel √¢ge a ce langage aujourd'hui ?\",\n",
        "]\n",
        "\n",
        "for q in questions:\n",
        "    agent.resoudre(q)\n",
        "    print(\"\\n\" + \"-\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "254bf3e3",
      "metadata": {
        "id": "254bf3e3"
      },
      "source": [
        "---\n",
        "\n",
        "## Partie 7 : √âvaluation des LLMs\n",
        "\n",
        "### M√©triques d'√âvaluation\n",
        "\n",
        "| M√©trique | Description | Utilisation |\n",
        "|----------|-------------|-------------|\n",
        "| **Exactitude** | Correspondance exacte | Classification, QA ferm√© |\n",
        "| **BLEU/ROUGE** | Similarit√© de texte | Traduction, r√©sum√© |\n",
        "| **Coherence** | Logique du discours | G√©n√©ration longue |\n",
        "| **Faithfulness** | Fid√©lit√© aux sources | RAG, r√©sum√© |\n",
        "| **G-Eval** | √âvaluation par LLM | Tout type de t√¢che |\n",
        "\n",
        "### Pratique : √âvaluation avec DeepEval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "1-aBZJr9gG87",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "1-aBZJr9gG87",
        "outputId": "44d770b6-03ba-4e00-a54c-b15d4e485dc0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfrom deepeval import evaluate\\nfrom deepeval.metrics import AnswerRelevancyMetric, FaithfulnessMetric\\nfrom deepeval.test_case import LLMTestCase\\n\\n# Cr√©er un cas de test\\ntest_case = LLMTestCase(\\n    input=\"Qu\\'est-ce que le machine learning ?\",\\n    actual_output=\"Le machine learning est une branche de l\\'IA...\",\\n    expected_output=\"Le machine learning est une technique d\\'apprentissage automatique...\",\\n    context=[\"Le ML est une sous-branche de l\\'intelligence artificielle.\"]\\n)\\n\\n# D√©finir les m√©triques\\nrelevancy_metric = AnswerRelevancyMetric(threshold=0.7)\\nfaithfulness_metric = FaithfulnessMetric(threshold=0.7)\\n\\n# √âvaluer\\nevaluate([test_case], [relevancy_metric, faithfulness_metric])\\n'"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "Exercice 7 : √âvaluation des LLMs\n",
        "Objectif : Mesurer et am√©liorer la qualit√© des r√©ponses\n",
        "\"\"\"\n",
        "\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# ============================================\n",
        "# 7.1 √âVALUATION MANUELLE STRUCTUR√âE\n",
        "# ============================================\n",
        "\n",
        "class EvaluateurManuel:\n",
        "    \"\"\"\n",
        "    √âvaluateur manuel avec crit√®res structur√©s.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, criteres: dict = None):\n",
        "        self.criteres = criteres or {\n",
        "            \"pertinence\": \"La r√©ponse r√©pond-elle √† la question pos√©e ?\",\n",
        "            \"exactitude\": \"Les informations sont-elles correctes ?\",\n",
        "            \"completude\": \"La r√©ponse est-elle compl√®te ?\",\n",
        "            \"clarte\": \"La r√©ponse est-elle claire et bien structur√©e ?\",\n",
        "            \"concision\": \"La r√©ponse est-elle concise sans √™tre trop courte ?\",\n",
        "        }\n",
        "\n",
        "    def evaluer_avec_llm(self, question: str, reponse: str, model: str = \"gpt-4o-mini\") -> dict:\n",
        "        \"\"\"\n",
        "        Utilise un LLM comme juge pour √©valuer une r√©ponse.\n",
        "        \"\"\"\n",
        "        prompt = f\"\"\"Tu es un √©valuateur expert. √âvalue la r√©ponse suivante selon les crit√®res donn√©s.\n",
        "\n",
        "        QUESTION: {question}\n",
        "\n",
        "        R√âPONSE √Ä √âVALUER: {reponse}\n",
        "\n",
        "        CRIT√àRES D'√âVALUATION:\n",
        "        {chr(10).join([f'- {k}: {v}' for k, v in self.criteres.items()])}\n",
        "\n",
        "        Pour chaque crit√®re, donne une note de 1 √† 5 et une justification br√®ve.\n",
        "        Termine par une note globale et un r√©sum√©.\n",
        "\n",
        "        Format de r√©ponse (JSON):\n",
        "        {{\n",
        "            \"scores\": {{\n",
        "                \"pertinence\": {{\"note\": X, \"justification\": \"...\"}},\n",
        "                \"exactitude\": {{\"note\": X, \"justification\": \"...\"}},\n",
        "                \"completude\": {{\"note\": X, \"justification\": \"...\"}},\n",
        "                \"clarte\": {{\"note\": X, \"justification\": \"...\"}},\n",
        "                \"concision\": {{\"note\": X, \"justification\": \"...\"}}\n",
        "            }},\n",
        "            \"note_globale\": X.X,\n",
        "            \"resume\": \"...\"\n",
        "        }}\"\"\"\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.1\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "# ============================================\n",
        "# 7.2 COMPARAISON A/B\n",
        "# ============================================\n",
        "\n",
        "class ComparateurAB:\n",
        "    \"\"\"\n",
        "    Compare deux variantes de prompts ou de mod√®les.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model: str = \"gpt-4o-mini\"):\n",
        "        self.model = model\n",
        "\n",
        "    def comparer(self, question: str, reponse_a: str, reponse_b: str) -> dict:\n",
        "        \"\"\"\n",
        "        Compare deux r√©ponses et d√©termine laquelle est meilleure.\n",
        "        \"\"\"\n",
        "        prompt = f\"\"\"Tu es un √©valuateur impartial. Compare les deux r√©ponses suivantes √† la m√™me question.\n",
        "\n",
        "        QUESTION: {question}\n",
        "\n",
        "        R√âPONSE A:\n",
        "        {reponse_a}\n",
        "\n",
        "        R√âPONSE B:\n",
        "        {reponse_b}\n",
        "\n",
        "        Analyse selon ces crit√®res:\n",
        "        1. Pertinence par rapport √† la question\n",
        "        2. Exactitude des informations\n",
        "        3. Clart√© et lisibilit√©\n",
        "        4. Utilit√© pratique\n",
        "\n",
        "        Donne ton verdict:\n",
        "        - Quelle r√©ponse est meilleure ?\n",
        "        - Pourquoi ?\n",
        "        - Y a-t-il des √©l√©ments √† combiner des deux r√©ponses ?\n",
        "\n",
        "        Format JSON:\n",
        "        {{\n",
        "            \"gagnant\": \"A\" ou \"B\" ou \"√©galit√©\",\n",
        "            \"raison\": \"...\",\n",
        "            \"score_a\": X/10,\n",
        "            \"score_b\": X/10,\n",
        "            \"suggestions\": \"...\"\n",
        "        }}\"\"\"\n",
        "\n",
        "        response = client.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.1\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "# ============================================\n",
        "# 7.3 √âVALUATION AVEC DEEPEVAL\n",
        "# ============================================\n",
        "\n",
        "def installer_deepeval():\n",
        "    \"\"\"Instructions pour installer DeepEval.\"\"\"\n",
        "    print(\"\"\"\n",
        "    Pour utiliser DeepEval, installez-le avec:\n",
        "    pip install deepeval\n",
        "\n",
        "    Puis configurez votre cl√© OpenAI:\n",
        "    export OPENAI_API_KEY=sk-...\n",
        "    \"\"\")\n",
        "\n",
        "# Exemple d'utilisation de DeepEval (√† d√©commenter apr√®s installation)\n",
        "\"\"\"\n",
        "from deepeval import evaluate\n",
        "from deepeval.metrics import AnswerRelevancyMetric, FaithfulnessMetric\n",
        "from deepeval.test_case import LLMTestCase\n",
        "\n",
        "# Cr√©er un cas de test\n",
        "test_case = LLMTestCase(\n",
        "    input=\"Qu'est-ce que le machine learning ?\",\n",
        "    actual_output=\"Le machine learning est une branche de l'IA...\",\n",
        "    expected_output=\"Le machine learning est une technique d'apprentissage automatique...\",\n",
        "    context=[\"Le ML est une sous-branche de l'intelligence artificielle.\"]\n",
        ")\n",
        "\n",
        "# D√©finir les m√©triques\n",
        "relevancy_metric = AnswerRelevancyMetric(threshold=0.7)\n",
        "faithfulness_metric = FaithfulnessMetric(threshold=0.7)\n",
        "\n",
        "# √âvaluer\n",
        "evaluate([test_case], [relevancy_metric, faithfulness_metric])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "mbZFho--gfFt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbZFho--gfFt",
        "outputId": "bcb127a8-9ac2-4241-8613-4da57c502d08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "EXERCICE 7 : √âVALUATION DES LLMS\n",
            "======================================================================\n",
            "\n",
            "√âvaluation de la r√©ponse:\n",
            "----------------------------------------\n",
            "{\n",
            "    \"scores\": {\n",
            "        \"pertinence\": {\"note\": 5, \"justification\": \"La r√©ponse aborde directement les avantages et inconv√©nients du t√©l√©travail, r√©pondant ainsi parfaitement √† la question pos√©e.\"},\n",
            "        \"exactitude\": {\"note\": 5, \"justification\": \"Les informations fournies sur les avantages et inconv√©nients du t√©l√©travail sont correctes et refl√®tent des r√©alit√©s g√©n√©ralement reconnues.\"},\n",
            "        \"completude\": {\"note\": 4, \"justification\": \"Bien que la r√©ponse couvre les principaux avantages et inconv√©nients, elle pourrait √™tre enrichie par des exemples ou des d√©tails suppl√©mentaires.\"},\n",
            "        \"clarte\": {\"note\": 5, \"justification\": \"La r√©ponse est bien structur√©e, avec une s√©paration claire entre les avantages et les inconv√©nients, ce qui facilite la compr√©hension.\"},\n",
            "        \"concision\": {\"note\": 5, \"justification\": \"La r√©ponse est concise et va droit au but, sans informations superflues.\"}\n",
            "    },\n",
            "    \"note_globale\": 4.8,\n",
            "    \"resume\": \"La r√©ponse est pertinente, exacte, claire et concise, bien qu'elle pourrait √™tre l√©g√®rement plus compl√®te. Elle r√©pond efficacement √† la question sur les avantages et inconv√©nients du t√©l√©travail.\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"EXERCICE 7 : √âVALUATION DES LLMS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Exercice 7.1 : √âvaluation d'une r√©ponse\n",
        "evaluateur = EvaluateurManuel()\n",
        "\n",
        "question_test = \"Quels sont les avantages et inconv√©nients du t√©l√©travail ?\"\n",
        "reponse_test = \"\"\"\n",
        "Le t√©l√©travail pr√©sente plusieurs avantages :\n",
        "- Flexibilit√© des horaires\n",
        "- √âconomie de temps de transport\n",
        "- Meilleur √©quilibre vie professionnelle/personnelle\n",
        "\n",
        "Les inconv√©nients incluent :\n",
        "- Isolement social\n",
        "- Difficult√© √† s√©parer vie pro et perso\n",
        "- Risque de surmenage\n",
        "\n",
        "En conclusion, le t√©l√©travail peut √™tre b√©n√©fique si bien encadr√©.\n",
        "\"\"\"\n",
        "\n",
        "print(\"\\n√âvaluation de la r√©ponse:\")\n",
        "print(\"-\"*40)\n",
        "evaluation = evaluateur.evaluer_avec_llm(question_test, reponse_test)\n",
        "print(evaluation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "BhIQZEtbgqfJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhIQZEtbgqfJ",
        "outputId": "91138fc3-10ee-49ed-ca81-9be01446f690"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Comparaison A/B:\n",
            "----------------------------------------\n",
            "```json\n",
            "{\n",
            "    \"gagnant\": \"B\",\n",
            "    \"raison\": \"La r√©ponse B est plus structur√©e, d√©taill√©e et couvre √† la fois les avantages et les inconv√©nients du t√©l√©travail de mani√®re √©quilibr√©e. Elle fournit des informations pr√©cises et des recommandations pratiques, ce qui la rend plus utile.\",\n",
            "    \"score_a\": 4/10,\n",
            "    \"score_b\": 9/10,\n",
            "    \"suggestions\": \"La r√©ponse A pourrait √™tre am√©lior√©e en ajoutant des d√©tails et en structurant les id√©es de mani√®re plus claire, tout en conservant un ton l√©ger. Des √©l√©ments de la r√©ponse A, comme le travail en pyjama, pourraient √™tre int√©gr√©s dans la r√©ponse B pour ajouter une touche personnelle.\"\n",
            "}\n",
            "```\n"
          ]
        }
      ],
      "source": [
        "# Exercice 7.2 : Comparaison A/B de prompts\n",
        "print(\"\\n\\nComparaison A/B:\")\n",
        "print(\"-\"*40)\n",
        "\n",
        "comparateur = ComparateurAB()\n",
        "\n",
        "# Deux versions de r√©ponses g√©n√©r√©es avec diff√©rents prompts\n",
        "reponse_prompt_simple = \"\"\"Le t√©l√©travail c'est bien car on ne perd pas de temps dans les transports et on peut travailler en pyjama. Mais c'est aussi nul car on ne voit plus personne.\"\"\"\n",
        "\n",
        "reponse_prompt_structure = \"\"\"\n",
        "## Avantages du t√©l√©travail\n",
        "\n",
        "1. **Gain de temps** : √âlimination des trajets domicile-travail\n",
        "2. **Flexibilit√©** : Meilleure gestion de son emploi du temps\n",
        "3. **Productivit√©** : Environnement souvent plus calme\n",
        "\n",
        "## Inconv√©nients du t√©l√©travail\n",
        "\n",
        "1. **Isolement** : R√©duction des interactions sociales\n",
        "2. **Fronti√®res floues** : Difficult√© √† \"d√©brancher\"\n",
        "3. **Communication** : Collaboration parfois plus complexe\n",
        "\n",
        "## Recommandations\n",
        "\n",
        "Un mod√®le hybride (2-3 jours en pr√©sentiel) semble √™tre le meilleur compromis.\n",
        "\"\"\"\n",
        "\n",
        "resultat_comparaison = comparateur.comparer(\n",
        "    question_test,\n",
        "    reponse_prompt_simple,\n",
        "    reponse_prompt_structure\n",
        ")\n",
        "print(resultat_comparaison)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
